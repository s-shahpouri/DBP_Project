{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from dual_network_3f import Dual3DCNN6 as Dual\n",
    "# from dual_network import Dual3DCNN6 as Dual\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import glob\n",
    "from utilities import create_list_from_master_json, read_json_file, split_data\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from utilities import list_patient_folders, prepare_data_nrrd, split_data\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, ScaleIntensityd, SpatialPadd, CenterSpatialCropd, ScaleIntensityRanged\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.transforms import LoadImaged\n",
    "from monai.data.image_reader import ITKReader\n",
    "from monai.data import SmartCacheDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 65\n",
      "Number of validation samples: 67\n",
      "Number of test samples: 43\n"
     ]
    }
   ],
   "source": [
    "from utilities import list_patient_folders, prepare_data_nrrd, split_data\n",
    "\n",
    "# Specify the directory where the patient folders are located\n",
    "data_path_NEW = '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test'\n",
    "# data_path_OLD = '/home/shahpouriz/Data/DBP_oldDATA/nrrd/test'\n",
    "\n",
    "import random\n",
    "patient_list_NEW = list_patient_folders(data_path_NEW)\n",
    "# Shuffle patient list if you want randomness\n",
    "random.shuffle(patient_list_NEW)\n",
    "\n",
    "# Define split sizes\n",
    "total_patients = len(patient_list_NEW)\n",
    "train_size = int(total_patients * 0.7)\n",
    "val_size = int(total_patients * 0.20)\n",
    "# The rest will be for the test set\n",
    "\n",
    "# Split the patient list\n",
    "train_patients = patient_list_NEW[:train_size]\n",
    "val_patients = patient_list_NEW[train_size:train_size + val_size]\n",
    "test_patients = patient_list_NEW[train_size + val_size:]\n",
    "\n",
    "# Now you can prepare your data\n",
    "# This step will depend on how your 'prepare_data_nrrd' function works\n",
    "# You need to pass the right patient list to this function for each set\n",
    "train_pct, train_rct, train_pos = prepare_data_nrrd(data_path_NEW, train_patients)\n",
    "val_pct, val_rct, val_pos = prepare_data_nrrd(data_path_NEW, val_patients)\n",
    "test_pct, test_rct, test_pos = prepare_data_nrrd(data_path_NEW, test_patients)\n",
    "\n",
    "# Create dictionaries for each dataset\n",
    "train_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(train_pct, train_rct, train_pos)]\n",
    "val_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(val_pct, val_rct, val_pos)]\n",
    "test_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(test_pct, test_rct, test_pos)]\n",
    "\n",
    "\n",
    "# Check the lengths of the sets\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(val_data))\n",
    "print(\"Number of test samples:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DBP_HN028',\n",
       " 'DBP_HN025',\n",
       " 'DBP_HN045',\n",
       " 'DBP_HN010',\n",
       " 'DBP_HN024',\n",
       " 'DBP_HN042',\n",
       " 'DBP_HN027',\n",
       " 'DBP_HN004',\n",
       " 'DBP_HN037',\n",
       " 'DBP_HN009',\n",
       " 'DBP_HN008',\n",
       " 'DBP_HN036',\n",
       " 'DBP_HN014',\n",
       " 'DBP_HN011',\n",
       " 'DBP_HN023',\n",
       " 'DBP_HN012',\n",
       " 'DBP_HN031',\n",
       " 'DBP_HN044',\n",
       " 'DBP_HN029',\n",
       " 'DBP_HN020',\n",
       " 'DBP_HN002',\n",
       " 'DBP_OP013',\n",
       " 'DBP_OP008',\n",
       " 'DBP_OP017',\n",
       " 'DBP_OP024',\n",
       " 'DBP_OP004',\n",
       " 'DBP_OP010',\n",
       " 'DBP_OP020',\n",
       " 'DBP_OP009',\n",
       " 'DBP_OP027',\n",
       " 'DBP_OP025',\n",
       " 'DBP_OP014',\n",
       " 'DBP_OP012',\n",
       " 'DBP_OP001',\n",
       " 'DBP_OP018',\n",
       " 'DBP_OP026',\n",
       " 'DBP_OP007',\n",
       " 'DBP_OP006',\n",
       " 'DBP_OP029',\n",
       " 'DBP_OP011',\n",
       " 'DBP_OP015',\n",
       " 'DBP_OP022',\n",
       " 'DBP_OP021',\n",
       " 'DBP_OP023',\n",
       " 'DBP_OP032',\n",
       " 'DBP_OP028',\n",
       " 'DBP_OP002']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT5.nrrd',\n",
       "  'pos': array([-0.71592,  0.21269,  1.25212], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT4.nrrd',\n",
       "  'pos': array([ 0.63696, -0.06812, -0.55098], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT1.nrrd',\n",
       "  'pos': array([ 0.04297, -0.09644,  0.06532], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT3.nrrd',\n",
       "  'pos': array([-0.44464, -1.54071, -0.64358], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT2.nrrd',\n",
       "  'pos': array([-1.16807,  0.6279 ,  0.93565], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP013/DBP_OP013_P1_repeatedCT6.nrrd',\n",
       "  'pos': array([-1.09257,  1.08421,  1.58153], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_repeatedCT2.nrrd',\n",
       "  'pos': array([-1.22804,  1.15984,  0.14225], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_repeatedCT4.nrrd',\n",
       "  'pos': array([-1.29908, -0.92432,  1.06912], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_repeatedCT1.nrrd',\n",
       "  'pos': array([-0.15274, -0.14693,  0.09734], dtype=float32)},\n",
       " {'plan': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_planningCT.nrrd',\n",
       "  'repeat': '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test/DBP_OP008/DBP_OP008_P1_repeatedCT3.nrrd',\n",
       "  'pos': array([ 0.07068,  1.26008, -0.0734 ], dtype=float32)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [{\"plan\": img[0], \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(pct[:10], rct[:10], pos[:10])]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "starting_epoch = 0\n",
    "# decay_epoch = 20\n",
    "final_epoch = 6\n",
    "# learning_rate = 0.0001\n",
    "lambda_reg = 0.000001\n",
    "\n",
    "# Condition for saving list\n",
    "# save_list = False\n",
    "best_mae = np.inf\n",
    "\n",
    "exception_list = ['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 85/85 [00:01<00:00, 52.84it/s]\n",
      "Loading dataset: 100%|██████████| 18/18 [00:00<00:00, 58.29it/s]\n"
     ]
    }
   ],
   "source": [
    "#### My method\n",
    "\n",
    "\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, SpatialPadd, CenterSpatialCropd, ScaleIntensityRanged\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.transforms import LoadImaged\n",
    "from monai.data.image_reader import ITKReader\n",
    "batch_size = 2\n",
    "dim = 128\n",
    "size = (dim, dim, dim)\n",
    "transforms = Compose([\n",
    "        LoadImaged(keys=[\"plan\", \"repeat\"], reader=ITKReader()),\n",
    "        EnsureChannelFirstd(keys=[\"plan\", \"repeat\"]),\n",
    "        ScaleIntensityd(keys=[\"plan\", \"repeat\"]),\n",
    "        Spacingd(keys=[\"plan\", \"repeat\"], pixdim=(3.0, 3.0, 3.0), mode='trilinear'),\n",
    "        SpatialPadd(keys=[\"plan\", \"repeat\"], spatial_size=size, mode='constant'),  # Ensure minimum size\n",
    "        CenterSpatialCropd(keys=[\"plan\", \"repeat\"], roi_size=size),  # Ensure uniform size\n",
    "    ])\n",
    "\n",
    "\n",
    "# train_ds = CacheDataset(data=train_data, transform=transforms, cache_rate=1.0, num_workers=2)\n",
    "# train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# val_ds = CacheDataset(data=val_data, transform=transforms, cache_rate=1.0, num_workers=2)\n",
    "# val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "train_ds = SmartCacheDataset(data=train_data, transform=transforms, cache_rate=0.1, replace_rate=0.2, num_init_workers=2, num_replace_workers=2)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "val_ds = SmartCacheDataset(data=val_data, transform=transforms, cache_rate=0.1, replace_rate=0.2, num_init_workers=2, num_replace_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, SpatialPadd, CenterSpatialCropd, ScaleIntensityRanged\n",
    "# from monai.data import CacheDataset, DataLoader, Dataset\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming `transforms` is defined and `val_files` contains your validation files\n",
    "# check_ds = Dataset(data=val_data, transform=transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1)\n",
    "\n",
    "# # Manually retrieve the first batch of data\n",
    "# for check_data in check_loader:\n",
    "#     break\n",
    "\n",
    "# plan, repeat = (check_data[\"plan\"][0][0], check_data[\"repeat\"][0][0])\n",
    "# print(f\"image shape: {plan.shape}, target shape: {repeat.shape}\")\n",
    "\n",
    "# # plot the slice [:, :, n]\n",
    "# n = 100\n",
    "\n",
    "# plt.figure(\"check\", (12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title(\"image\")\n",
    "# plt.imshow(plan[:, :, n], origin=\"lower\")\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title(\"repeat\")\n",
    "# plt.imshow(repeat[:, :, n])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr_finder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# def find_lr(model, train_loader, optimizer, init_value=1e-8, final_value=10., beta=0.98):\n",
    "#     num = len(train_loader)-1  # Total number of batches\n",
    "#     mult = (final_value / init_value) ** (1/num)\n",
    "#     lr = init_value\n",
    "#     optimizer.param_groups[0]['lr'] = lr\n",
    "#     avg_loss = 0.\n",
    "#     best_loss = 0.\n",
    "#     batch_num = 0\n",
    "#     losses = []\n",
    "#     log_lrs = []\n",
    "#     for data in train_loader:\n",
    "#         batch_num += 1\n",
    "#         # Get the input and target from the batch\n",
    "#         # This part needs to be adapted to your specific data loader structure\n",
    "#         # Adjust these lines to match how your data is structured and ensure both inputs are provided\n",
    "#         inputs_fixed = data[\"plan\"].to(device)\n",
    "#         inputs_moving = data[\"repeat\"].to(device)\n",
    "#         targets = data[\"pos\"].to(device)  # Assuming 'pos' is the target\n",
    "        \n",
    "#         # Forward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         # Make sure to pass both inputs to the model\n",
    "#         outputs = model(inputs_fixed, inputs_moving)  # Adjusted to pass both inputs\n",
    "#         # Assuming your model outputs in a format that matches targets, adjust if it outputs a tuple\n",
    "#         loss = mae_loss(outputs, targets)\n",
    "\n",
    "#         # Compute the smoothed loss\n",
    "#         avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "#         smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "\n",
    "#         # Stop if the loss is exploding\n",
    "#         if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "#             return log_lrs, losses\n",
    "\n",
    "#         # Record the best loss\n",
    "#         if smoothed_loss < best_loss or batch_num==1:\n",
    "#             best_loss = smoothed_loss\n",
    "\n",
    "#         # Store the values\n",
    "#         losses.append(smoothed_loss)\n",
    "#         log_lrs.append(np.log10(lr))\n",
    "\n",
    "#         # Do the backward pass and optimize\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Update the lr for the next step and store\n",
    "#         lr *= mult\n",
    "#         optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "#     return log_lrs, losses\n",
    "\n",
    "# # Call the function\n",
    "# model.train()\n",
    "# log_lrs, losses = find_lr(model, train_loader, optimizer)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.plot(log_lrs, losses)\n",
    "# plt.xlabel(\"Learning Rate (log scale)\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Defining loss...\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "print('Initializing model...')\n",
    "model = Dual(width=dim, height=dim, depth=dim)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss\n",
    "print('Defining loss...')\n",
    "mae_loss = torch.nn.L1Loss()\n",
    "# mae_loss = torch.nn.MSELoss()\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "learning_rate = 1e-3  # Start with a learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Scheduler (optional, to reduce learning rate when a metric has stopped improving)\n",
    "# Here, we use ReduceLROnPlateau which reduces learning rate when a metric stops improving\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1872,  1.0014], device='cuda:0')\n",
      "tensor([-0.1480,  0.1944], device='cuda:0')\n",
      "tensor([-0.8255,  1.2423], device='cuda:0')\n",
      "tensor([ 0.1336, -0.0396], device='cuda:0')\n",
      "tensor([-0.8695, -1.0548], device='cuda:0')\n",
      "tensor([ 0.3498, -1.0046], device='cuda:0')\n",
      "tensor([-1.1555,  0.4691], device='cuda:0')\n",
      "tensor([-1.0963, -0.7831], device='cuda:0')\n",
      "tensor([ 0.2657, -0.0995], device='cuda:0')\n",
      "tensor([-1.1872,  1.0014], device='cuda:0')\n",
      "tensor([-0.1480,  0.1944], device='cuda:0')\n",
      "tensor([-0.8255,  1.2423], device='cuda:0')\n",
      "tensor([ 0.1336, -0.0396], device='cuda:0')\n",
      "tensor([-0.8695, -1.0548], device='cuda:0')\n",
      "tensor([ 0.3498, -1.0046], device='cuda:0')\n",
      "tensor([-1.1555,  0.4691], device='cuda:0')\n",
      "tensor([-1.0963, -0.7831], device='cuda:0')\n",
      "tensor([ 0.2657, -0.0995], device='cuda:0')\n",
      "Model saved to /home/shahpouriz/Data/DBP_Project/LOG/loss_Model_3f_1p_2.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Assuming mae_loss is defined and using the correct device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 13\u001b[0m     pCT, rCT \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     reg \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# No need for clone().detach().requires_grad_(True) for targets\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/monai/data/meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "# Initialize best_mae before the training loop\n",
    "best_mae = float('inf')\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(starting_epoch, final_epoch):\n",
    "    model.train()  # Set model to training mode\n",
    "    mae_list = []\n",
    "    train_loss = []\n",
    "    # Assuming mae_loss is defined and using the correct device\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        pCT, rCT = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg = batch_data[\"pos\"].to(device)  # No need for clone().detach().requires_grad_(True) for targets\n",
    "        \n",
    "        # Forward pass\n",
    "        outx, outy, outz = model(pCT, rCT)\n",
    "        \n",
    "        # Split reg into its components (assuming reg has shape [batch_size, 3])\n",
    "        regx, regy, regz = reg[:, 0], reg[:, 1], reg[:, 2]\n",
    "\n",
    "        # Calculate MAE for each component\n",
    "        loss_x = mae_loss(outx, regx.unsqueeze(1))  # Add dimension to match output shape\n",
    "        loss_y = mae_loss(outy, regy.unsqueeze(1))\n",
    "        loss_z = mae_loss(outz, regz.unsqueeze(1))\n",
    "\n",
    "        # Combine the losses (you could also weigh them differently)\n",
    "        total_loss = (loss_x + loss_y + loss_z)/batch_size\n",
    "        train_losses.append(total_loss.item())\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging (example for total_loss, adjust as needed)\n",
    "        # print(f'Epoch: {epoch}/{final_epoch}, Batch: {i+1}/{len(train_loader)}, Loss: {total_loss.item()}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            pCT_val, rCT_val = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "            reg_val = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "            \n",
    "            # Model prediction\n",
    "            outx_val, outy_val, outz_val = model(pCT_val, rCT_val)\n",
    "       \n",
    "            # Split reg_val into its components\n",
    "            regx_val, regy_val, regz_val = reg_val[:, 0], reg_val[:, 1], reg_val[:, 2]\n",
    "          \n",
    "            # Calculate validation loss for each component\n",
    "            loss_val_x = mae_loss(outx_val, regx_val.unsqueeze(1))\n",
    "            loss_val_y = mae_loss(outy_val, regy_val.unsqueeze(1))\n",
    "            loss_val_z = mae_loss(outz_val, regz_val.unsqueeze(1))\n",
    "            \n",
    "            # Combine the losses\n",
    "            total_val_loss = (loss_val_x + loss_val_y + loss_val_z)/batch_size\n",
    "            print(regx_val)\n",
    "            val_losses.append(total_val_loss.item())\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        # print(f'Epoch [{epoch+1}/{final_epoch}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "        # Adjust learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # Saving model and logging\n",
    "        save_dir = '/home/shahpouriz/Data/DBP_Project/LOG'\n",
    "        filename = f'loss_Model_3f_1p'\n",
    "        loss_file = os.path.join(save_dir, f'{filename}.txt')\n",
    "\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        if avg_val_loss <= best_mae and epoch > 0:\n",
    "            best_mae = avg_val_loss\n",
    "            model_filename = f'{filename}_{epoch+1}.pt'  # Store the model filename\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, model_filename))\n",
    "            print(f'Model saved to {os.path.join(save_dir, model_filename)}')\n",
    "        \n",
    "        # Append current epoch's average loss and validation loss to the log file\n",
    "        with open(loss_file, 'a') as f:\n",
    "            f.write(f'Epoch: {epoch+1}/{final_epoch}, Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\\n')\n",
    "            # f.write(f'Epoch: {epoch+1}/{final_epoch}, Loss: {avg_train_loss}, Val: {mean_val_loss}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize best_mae before the training loop\n",
    "# best_mae = float('inf')\n",
    "# train_losses = []\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(starting_epoch, final_epoch):\n",
    "#     model.train()  # Set model to training mode\n",
    "#     mae_list = []\n",
    "#     train_loss = []\n",
    "#     # Assuming mae_loss is defined and using the correct device\n",
    "#     for i, batch_data in enumerate(train_loader):\n",
    "#         pCT, rCT = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "#         reg = batch_data[\"pos\"].to(device)  # No need for clone().detach().requires_grad_(True) for targets\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outx, outy, outz = model(pCT, rCT)\n",
    "        \n",
    "#         # Split reg into its components (assuming reg has shape [batch_size, 3])\n",
    "#         regx, regy, regz = reg[:, 0], reg[:, 1], reg[:, 2]\n",
    "\n",
    "#         # Calculate MAE for each component\n",
    "#         loss_x = mae_loss(outx, regx.unsqueeze(1))  # Add dimension to match output shape\n",
    "#         loss_y = mae_loss(outy, regy.unsqueeze(1))\n",
    "#         loss_z = mae_loss(outz, regz.unsqueeze(1))\n",
    "\n",
    "#         # Combine the losses (you could also weigh them differently)\n",
    "#         total_loss = (loss_x + loss_y + loss_z)/batch_size\n",
    "#         train_losses.append(total_loss.item())\n",
    "        \n",
    "#         # Calculate average validation loss\n",
    "#         avg_train_loss = np.mean(train_losses)\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss.backward()\n",
    "#         # loss_y.backward()\n",
    "#         # loss_z.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Logging (example for total_loss, adjust as needed)\n",
    "#         print(f'Epoch: {epoch}/{final_epoch}, Batch: {i+1}/{len(train_loader)}, Loss: {total_loss.item()}')\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     val_losses = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch_data in val_loader:\n",
    "#             pCT_val, rCT_val = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "#             reg_val = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "            \n",
    "#             # Model prediction\n",
    "#             outx_val, outy_val, outz_val = model(pCT_val, rCT_val)\n",
    "#             print(outx_val, outy_val, outz_val)\n",
    "#             # Split reg_val into its components\n",
    "#             regx_val, regy_val, regz_val = reg_val[:, 0], reg_val[:, 1], reg_val[:, 2]\n",
    "#             print(regx_val, regy_val, regz_val)\n",
    "#             # Calculate validation loss for each component\n",
    "#             loss_val_x = mae_loss(outx_val, regx_val.unsqueeze(1))\n",
    "#             loss_val_y = mae_loss(outy_val, regy_val.unsqueeze(1))\n",
    "#             loss_val_z = mae_loss(outz_val, regz_val.unsqueeze(1))\n",
    "            \n",
    "#             # Combine the losses\n",
    "#             total_val_loss = (loss_val_x + loss_val_y + loss_val_z)/batch_size\n",
    "            \n",
    "#             val_losses.append(total_val_loss.item())\n",
    "        \n",
    "#         # Calculate average validation loss\n",
    "#         avg_val_loss = np.mean(val_losses)\n",
    "#         print(f'Epoch [{epoch+1}/{final_epoch}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "#         # Adjust learning rate\n",
    "#         lr_scheduler.step()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         # Saving model and logging\n",
    "#         save_dir = '/home/shahpouriz/Data/DBP_Project/LOG'\n",
    "#         filename = f'loss_Model_3f'\n",
    "#         loss_file = os.path.join(save_dir, f'{filename}.txt')\n",
    "\n",
    "#         if not os.path.isdir(save_dir):\n",
    "#             os.makedirs(save_dir)\n",
    "        \n",
    "#         if avg_val_loss <= best_mae and epoch > 0:\n",
    "#             best_mae = avg_val_loss\n",
    "#             model_filename = f'{filename}_{epoch+1}.pt'  # Store the model filename\n",
    "#             torch.save(model.state_dict(), os.path.join(save_dir, model_filename))\n",
    "#             print(f'Model saved to {os.path.join(save_dir, model_filename)}')\n",
    "        \n",
    "#         # Append current epoch's average loss and validation loss to the log file\n",
    "#         with open(loss_file, 'a') as f:\n",
    "#             f.write(f'Epoch: {epoch+1}/{final_epoch}, Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\\n')\n",
    "#             # f.write(f'Epoch: {epoch+1}/{final_epoch}, Loss: {avg_train_loss}, Val: {mean_val_loss}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "tensor([[-0.8186, -0.2103, -1.5246],\n",
      "        [-1.0367, -0.3661,  0.6014]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "(metatensor([[-0.2432],\n",
      "        [-0.2429]], device='cuda:0', grad_fn=<AliasBackward0>), metatensor([[-0.0306],\n",
      "        [-0.0305]], device='cuda:0', grad_fn=<AliasBackward0>), metatensor([[0.0992],\n",
      "        [0.0991]], device='cuda:0', grad_fn=<AliasBackward0>))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m output \u001b[38;5;241m=\u001b[39m model(pCT, rCT)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m---> 16\u001b[0m loss_output \u001b[38;5;241m=\u001b[39m \u001b[43mmae_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_output)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# L1 Regularization\u001b[39;00m\n",
      "File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/nn/modules/loss.py:101\u001b[0m, in \u001b[0;36mL1Loss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Data/new_env/lib64/python3.11/site-packages/torch/nn/functional.py:3253\u001b[0m, in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[1;32m   3250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3251\u001b[0m         l1_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[1;32m   3252\u001b[0m     )\n\u001b[0;32m-> 3253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()):\n\u001b[1;32m   3254\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()),\n\u001b[1;32m   3258\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   3259\u001b[0m     )\n\u001b[1;32m   3260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(starting_epoch, final_epoch):\n",
    "    \n",
    "    # model.train()  # Set model to training mode\n",
    "    mae_list = []\n",
    "    train_loss = []\n",
    "    for i, batch_data in enumerate(train_loader):  # Use enumerate to get the batch index\n",
    "        pCT, rCT = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg = batch_data[\"pos\"].clone().detach().requires_grad_(True).to(device)  # If gradients are required for 'reg'\n",
    "        print(\"*****************************************\")\n",
    "        print(reg)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(pCT, rCT)\n",
    "        print(output)\n",
    "        loss_output = mae_loss(output, reg)\n",
    "        print(loss_output)\n",
    "\n",
    "\n",
    "        # L1 Regularization\n",
    "        l1_reg = torch.tensor(0., requires_grad=True).to(device)\n",
    "        for name, param in model.named_parameters():\n",
    "            l1_reg = l1_reg + torch.norm(param, 1)\n",
    "        loss_output += lambda_reg * l1_reg\n",
    "        print(loss_output)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss_output.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        mae_list.append(loss_output.item())\n",
    "        mean_mae = np.mean(mae_list)\n",
    "        # Corrected to print the current batch number\n",
    "        print(f'Epoch: {epoch}/{final_epoch}, Batch: {i+1}/{len(train_loader)}, Loss_avg: {mean_mae}')\n",
    "\n",
    "    # Validation loop\n",
    "    # model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            pCT_val, rCT_val = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "            reg_val = batch_data[\"pos\"].clone().detach().requires_grad_(True).to(device)  # If gradients are required for 'reg'\n",
    "\n",
    "            output_val = model(pCT_val, rCT_val)\n",
    "            loss_output_val = mae_loss(output_val, reg_val)\n",
    "\n",
    "            val_loss.append(loss_output_val.item())\n",
    "\n",
    "            mean_val_loss = np.mean(val_loss)\n",
    "            print(f'Epoch [{epoch+1}/{final_epoch}], Validation Loss: {mean_val_loss:.4f}')\n",
    "\n",
    "    # Adjust learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    save_dir = '/home/shahpouriz/Data/DBP_Project/LOG'\n",
    "    filename = f'loss_simple_Model_{dim}'\n",
    "    loss_file = fr'/home/shahpouriz/Data/DBP_Project/LOG/{filename}.txt'\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    current_valid_mae = val_loss[-1]    \n",
    "    print(f'Epoch: {epoch+1}, Current Valid MAE: {current_valid_mae}, Best MAE: {best_mae}')\n",
    "    if current_valid_mae <= best_mae and epoch > 0:\n",
    "        best_mae = current_valid_mae\n",
    "        model_filename = f'{filename}_{epoch+1}.pt'\n",
    "        model_path = f'{save_dir}/{model_filename}'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f'Model saved: {model_path}')\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for pct_tensor, rct_tensor, pos in train_dataset:\n",
    "#     print(\"pCT Tensor:\", pct_tensor.shape)\n",
    "#     print(\"rCT Tensor:\", rct_tensor.shape)\n",
    "#     print(\"Position:\", pos)\n",
    "#     count += 1\n",
    "#     if count == 1:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Build model\n",
    "# print('Initializing model...')\n",
    "# model = Dual(width=512, height=512, depth=512)\n",
    "# device = torch.device(f\"cuda:{device_num}\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Define loss\n",
    "# print('Defining loss...')\n",
    "# mae_loss = torch.nn.L1Loss()\n",
    "# mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# # Define optimizer\n",
    "# print('Defining optimizer...')\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# # Define scheduler\n",
    "# print('Defining scheduler...')\n",
    "# lr_lambda = DecayLR(epochs=final_epoch, offset=0, decay_epochs=decay_epoch).step\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize model\n",
    "# model = Dual(width=512, height=512, depth=512)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Define loss\n",
    "# mae_loss = torch.nn.L1Loss()\n",
    "# mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# # Define optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# # Define scheduler\n",
    "# lr_lambda = DecayLR(epochs=final_epoch, offset=0, decay_epochs=decay_epoch).step\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(starting_epoch, final_epoch):\n",
    "#     mae_list = []\n",
    "#     model.train()  # Set model to training mode\n",
    "#     for i, (pCT, rCT, reg) in enumerate(train_loader):\n",
    "#         pCT = pCT.to(device)\n",
    "#         rCT = rCT.to(device)\n",
    "#         reg = reg = reg[0].unsqueeze(1).to(device)  # Access the element of the list and move it to the device\n",
    "\n",
    "\n",
    "        \n",
    "#         # Forward pass\n",
    "#         output = model(pCT, rCT)\n",
    "#         output = output.to(torch.float32)\n",
    "#         reg = reg.to(torch.float32)\n",
    "#         # Calculate loss\n",
    "#         loss_output = mse_loss(output, reg)\n",
    "\n",
    "            \n",
    "#         # L1 Regularization\n",
    "#         l1_reg = torch.tensor(0., requires_grad=True).to(device)\n",
    "#         for name, param in model.named_parameters():\n",
    "#             l1_reg = l1_reg + torch.norm(param, 1)\n",
    "#         loss_output += lambda_reg * l1_reg\n",
    "        \n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss_output.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Logging\n",
    "#         mae_list.append(loss_output.item())\n",
    "#         mean_mae = np.mean(mae_list)\n",
    "#         print(f'Epoch: {epoch}/{final_epoch}, Batch: {i}/{len(train_loader)}, Loss_avg: {mean_mae}')\n",
    "    \n",
    "#     # Validation loop\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     val_loss = []\n",
    "#     with torch.no_grad():\n",
    "#         for j, (pCT_val, rCT_val, reg_val) in enumerate(val_loader):\n",
    "#             pCT_val = pCT_val.to(device)\n",
    "#             rCT_val = rCT_val.to(device)\n",
    "#             reg_val = reg_val.to(device)\n",
    "            \n",
    "#             output_val = model(pCT_val, rCT_val)\n",
    "#             loss_output_val = mae_loss(output_val, reg_val)\n",
    "            \n",
    "#             val_loss.append(loss_output_val.item())\n",
    "#             mean_val_loss = np.mean(val_loss)\n",
    "#             print(f'Epoch: {epoch}/{final_epoch}, Batch: {j}/{len(val_loader)}, Loss_avg: {mean_val_loss}')\n",
    "    \n",
    "#     # Adjust learning rate\n",
    "#     lr_scheduler.step(mean_val_loss)\n",
    "    \n",
    "#     save_dir = '/home/shahpouriz/Data/DBP_Project/LOG'\n",
    "#     fname_comment = 'test'\n",
    "#     loss_file = fr'/home/shahpouriz/Data/DBP_Project/LOG/loss_dose_json_simpleModel_{fname_comment}.txt'\n",
    "\n",
    "#     # Save model\n",
    "#     if not os.path.isdir(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "    \n",
    "#     current_valid_mae = val_loss[-1]    \n",
    "#     if current_valid_mae <= best_mae and epoch > 0:\n",
    "#         best_mae = current_valid_mae\n",
    "#         torch.save(model.state_dict(),f'{save_dir}/model_weights_dose_{epoch+1}_{fname_comment}.pt')\n",
    "#     with open(loss_file, 'a') as f: #a-append\n",
    "#         f.write(f'Epoch: {epoch+1}/{final_epoch}, Loss: {mean_mae}, Val: {mean_val_loss}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
