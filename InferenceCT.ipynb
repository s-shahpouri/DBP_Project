{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# from dual_network import Dual3DCNN6 as Dual\n",
    "from decayLR import DecayLR\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import glob\n",
    "from utilities import create_list_from_master_json, read_json_file, split_data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "Training Losses: [10.173321262482673, 7.410941631563248, 7.008255389428908, 6.7039098278168705, 6.533476629564839, 6.492760673646004, 6.339594133438602, 6.326135927631009, 6.332643908839072, 6.215676646078786, 6.199374475786763, 6.19963284461729, 6.164883244422175, 6.14712978178455, 6.162849318596624, 6.103065859886907, 6.067870832258655, 6.0905032465534825, 6.107838707585489, 6.064329224248087, 6.057978860793575, 6.046493253400249, 5.9677022195631455, 6.068731338747086, 5.913550269219183, 5.866663963563981, 5.844537611930601, 5.858050346374512, 5.855190707791236, 5.8122999283575245, 5.8056469425078365, 5.816736698150635, 5.816037516440114, 5.847229772998441, 5.799741975722775, 5.841159128373669, 5.817716398546772, 5.826847645544237, 5.775268385487218, 5.788922725185271, 5.7999827938695105, 5.833145203128938, 5.834849803678451, 5.827017261135962, 5.797139767677553, 5.834971920136483, 5.834017876655825, 5.7780502380863314, 5.8493409618254635, 5.8204895142586]\n",
      "Validation Losses: [7.458063776294391, 7.286813758313656, 7.037418337663015, 6.626706438014905, 7.827299116551876, 6.769813926517964, 9.035120700796446, 6.680800733466943, 6.456798662990332, 6.635956634581089, 6.22813256730636, 6.362288365761439, 6.407494433969259, 6.433090079327425, 6.45341512610515, 5.977973246077696, 6.570273294051488, 5.882647534708182, 5.96731440226237, 6.141708275675773, 6.2946148549517, 6.225412599245707, 7.275475724538167, 6.109281359612941, 6.0394425248106325, 6.134553797046343, 6.101148352026939, 6.128651245435079, 6.0957833970586455, 6.1085436602433525, 6.077391090989113, 6.08585768888394, 6.083798488477866, 6.083370262384415, 6.086282580594221, 6.07359539270401, 6.087334063152472, 6.085816042125225, 6.095939626793067, 6.084656250476837, 6.101407463351886, 6.082753171026707, 6.0883144468069075, 6.097826967140039, 6.087281721333663, 6.079045726855596, 6.090269591410955, 6.091889155407746, 6.102703668673834, 6.0840957100192705]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "directory = '/home/shahpouriz/Data/LOG/LOG_CT'\n",
    "loss_file_path = f'{directory}/LOG_CT/cnn4_128_0.01.txt'\n",
    "loss_file_path = f'{directory}/cnn4_128_0.01_scaleintensity.txt'\n",
    "loss_file_path = f'{directory}/LOG_CT/cnn4_128_0.01_scaleintensity+noise.txt'\n",
    "loss_file_path = f'{directory}/cnn4_128_0.01_5_16.txt'\n",
    "loss_file_path = f'{directory}/loss_5_16_14.txt'\n",
    "loss_file_path = f'{directory}/loss_5_17_6.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "start_epoch = 0  # Define the start epoch from which you want to plot\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epoch_num = int(match_epoch.group(1))\n",
    "            if epoch_num >= start_epoch:  # Only add data from the start_epoch onwards\n",
    "                epochs.append(epoch_num)\n",
    "                training_losses.append(float(match_epoch.group(2)))\n",
    "                validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch_info</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Validation</th>\n",
       "      <th>loss</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epoch: 1/50</td>\n",
       "      <td>Loss: 10.173321262482673</td>\n",
       "      <td>Val: 7.458063776294391</td>\n",
       "      <td>10.173321</td>\n",
       "      <td>7.458064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epoch: 2/50</td>\n",
       "      <td>Loss: 7.410941631563248</td>\n",
       "      <td>Val: 7.286813758313656</td>\n",
       "      <td>7.410942</td>\n",
       "      <td>7.286814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Epoch: 3/50</td>\n",
       "      <td>Loss: 7.008255389428908</td>\n",
       "      <td>Val: 7.037418337663015</td>\n",
       "      <td>7.008255</td>\n",
       "      <td>7.037418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epoch: 4/50</td>\n",
       "      <td>Loss: 6.7039098278168705</td>\n",
       "      <td>Val: 6.626706438014905</td>\n",
       "      <td>6.703910</td>\n",
       "      <td>6.626706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Epoch: 5/50</td>\n",
       "      <td>Loss: 6.533476629564839</td>\n",
       "      <td>Val: 7.827299116551876</td>\n",
       "      <td>6.533477</td>\n",
       "      <td>7.827299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Epoch: 6/50</td>\n",
       "      <td>Loss: 6.492760673646004</td>\n",
       "      <td>Val: 6.769813926517964</td>\n",
       "      <td>6.492761</td>\n",
       "      <td>6.769814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Epoch: 7/50</td>\n",
       "      <td>Loss: 6.339594133438602</td>\n",
       "      <td>Val: 9.035120700796446</td>\n",
       "      <td>6.339594</td>\n",
       "      <td>9.035121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Epoch: 8/50</td>\n",
       "      <td>Loss: 6.326135927631009</td>\n",
       "      <td>Val: 6.680800733466943</td>\n",
       "      <td>6.326136</td>\n",
       "      <td>6.680801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Epoch: 9/50</td>\n",
       "      <td>Loss: 6.332643908839072</td>\n",
       "      <td>Val: 6.456798662990332</td>\n",
       "      <td>6.332644</td>\n",
       "      <td>6.456799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Epoch: 10/50</td>\n",
       "      <td>Loss: 6.215676646078786</td>\n",
       "      <td>Val: 6.635956634581089</td>\n",
       "      <td>6.215677</td>\n",
       "      <td>6.635957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Epoch: 11/50</td>\n",
       "      <td>Loss: 6.199374475786763</td>\n",
       "      <td>Val: 6.22813256730636</td>\n",
       "      <td>6.199374</td>\n",
       "      <td>6.228133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Epoch: 12/50</td>\n",
       "      <td>Loss: 6.19963284461729</td>\n",
       "      <td>Val: 6.362288365761439</td>\n",
       "      <td>6.199633</td>\n",
       "      <td>6.362288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Epoch: 13/50</td>\n",
       "      <td>Loss: 6.164883244422175</td>\n",
       "      <td>Val: 6.407494433969259</td>\n",
       "      <td>6.164883</td>\n",
       "      <td>6.407494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Epoch: 14/50</td>\n",
       "      <td>Loss: 6.14712978178455</td>\n",
       "      <td>Val: 6.433090079327425</td>\n",
       "      <td>6.147130</td>\n",
       "      <td>6.433090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Epoch: 15/50</td>\n",
       "      <td>Loss: 6.162849318596624</td>\n",
       "      <td>Val: 6.45341512610515</td>\n",
       "      <td>6.162849</td>\n",
       "      <td>6.453415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Epoch: 16/50</td>\n",
       "      <td>Loss: 6.103065859886907</td>\n",
       "      <td>Val: 5.977973246077696</td>\n",
       "      <td>6.103066</td>\n",
       "      <td>5.977973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Epoch: 17/50</td>\n",
       "      <td>Loss: 6.067870832258655</td>\n",
       "      <td>Val: 6.570273294051488</td>\n",
       "      <td>6.067871</td>\n",
       "      <td>6.570273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Epoch: 18/50</td>\n",
       "      <td>Loss: 6.0905032465534825</td>\n",
       "      <td>Val: 5.882647534708182</td>\n",
       "      <td>6.090503</td>\n",
       "      <td>5.882648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Epoch: 19/50</td>\n",
       "      <td>Loss: 6.107838707585489</td>\n",
       "      <td>Val: 5.96731440226237</td>\n",
       "      <td>6.107839</td>\n",
       "      <td>5.967314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Epoch: 20/50</td>\n",
       "      <td>Loss: 6.064329224248087</td>\n",
       "      <td>Val: 6.141708275675773</td>\n",
       "      <td>6.064329</td>\n",
       "      <td>6.141708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Epoch: 21/50</td>\n",
       "      <td>Loss: 6.057978860793575</td>\n",
       "      <td>Val: 6.2946148549517</td>\n",
       "      <td>6.057979</td>\n",
       "      <td>6.294615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Epoch: 22/50</td>\n",
       "      <td>Loss: 6.046493253400249</td>\n",
       "      <td>Val: 6.225412599245707</td>\n",
       "      <td>6.046493</td>\n",
       "      <td>6.225413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Epoch: 23/50</td>\n",
       "      <td>Loss: 5.9677022195631455</td>\n",
       "      <td>Val: 7.275475724538167</td>\n",
       "      <td>5.967702</td>\n",
       "      <td>7.275476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Epoch: 24/50</td>\n",
       "      <td>Loss: 6.068731338747086</td>\n",
       "      <td>Val: 6.109281359612941</td>\n",
       "      <td>6.068731</td>\n",
       "      <td>6.109281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Epoch: 25/50</td>\n",
       "      <td>Loss: 5.913550269219183</td>\n",
       "      <td>Val: 6.0394425248106325</td>\n",
       "      <td>5.913550</td>\n",
       "      <td>6.039443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Epoch: 26/50</td>\n",
       "      <td>Loss: 5.866663963563981</td>\n",
       "      <td>Val: 6.134553797046343</td>\n",
       "      <td>5.866664</td>\n",
       "      <td>6.134554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Epoch: 27/50</td>\n",
       "      <td>Loss: 5.844537611930601</td>\n",
       "      <td>Val: 6.101148352026939</td>\n",
       "      <td>5.844538</td>\n",
       "      <td>6.101148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Epoch: 28/50</td>\n",
       "      <td>Loss: 5.858050346374512</td>\n",
       "      <td>Val: 6.128651245435079</td>\n",
       "      <td>5.858050</td>\n",
       "      <td>6.128651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Epoch: 29/50</td>\n",
       "      <td>Loss: 5.855190707791236</td>\n",
       "      <td>Val: 6.0957833970586455</td>\n",
       "      <td>5.855191</td>\n",
       "      <td>6.095783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Epoch: 30/50</td>\n",
       "      <td>Loss: 5.8122999283575245</td>\n",
       "      <td>Val: 6.1085436602433525</td>\n",
       "      <td>5.812300</td>\n",
       "      <td>6.108544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Epoch: 31/50</td>\n",
       "      <td>Loss: 5.8056469425078365</td>\n",
       "      <td>Val: 6.077391090989113</td>\n",
       "      <td>5.805647</td>\n",
       "      <td>6.077391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Epoch: 32/50</td>\n",
       "      <td>Loss: 5.816736698150635</td>\n",
       "      <td>Val: 6.08585768888394</td>\n",
       "      <td>5.816737</td>\n",
       "      <td>6.085858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Epoch: 33/50</td>\n",
       "      <td>Loss: 5.816037516440114</td>\n",
       "      <td>Val: 6.083798488477866</td>\n",
       "      <td>5.816038</td>\n",
       "      <td>6.083798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Epoch: 34/50</td>\n",
       "      <td>Loss: 5.847229772998441</td>\n",
       "      <td>Val: 6.083370262384415</td>\n",
       "      <td>5.847230</td>\n",
       "      <td>6.083370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Epoch: 35/50</td>\n",
       "      <td>Loss: 5.799741975722775</td>\n",
       "      <td>Val: 6.086282580594221</td>\n",
       "      <td>5.799742</td>\n",
       "      <td>6.086283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Epoch: 36/50</td>\n",
       "      <td>Loss: 5.841159128373669</td>\n",
       "      <td>Val: 6.07359539270401</td>\n",
       "      <td>5.841159</td>\n",
       "      <td>6.073595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Epoch: 37/50</td>\n",
       "      <td>Loss: 5.817716398546772</td>\n",
       "      <td>Val: 6.087334063152472</td>\n",
       "      <td>5.817716</td>\n",
       "      <td>6.087334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Epoch: 38/50</td>\n",
       "      <td>Loss: 5.826847645544237</td>\n",
       "      <td>Val: 6.085816042125225</td>\n",
       "      <td>5.826848</td>\n",
       "      <td>6.085816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Epoch: 39/50</td>\n",
       "      <td>Loss: 5.775268385487218</td>\n",
       "      <td>Val: 6.095939626793067</td>\n",
       "      <td>5.775268</td>\n",
       "      <td>6.095940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Epoch: 40/50</td>\n",
       "      <td>Loss: 5.788922725185271</td>\n",
       "      <td>Val: 6.084656250476837</td>\n",
       "      <td>5.788923</td>\n",
       "      <td>6.084656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Epoch: 41/50</td>\n",
       "      <td>Loss: 5.7999827938695105</td>\n",
       "      <td>Val: 6.101407463351886</td>\n",
       "      <td>5.799983</td>\n",
       "      <td>6.101407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Epoch: 42/50</td>\n",
       "      <td>Loss: 5.833145203128938</td>\n",
       "      <td>Val: 6.082753171026707</td>\n",
       "      <td>5.833145</td>\n",
       "      <td>6.082753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Epoch: 43/50</td>\n",
       "      <td>Loss: 5.834849803678451</td>\n",
       "      <td>Val: 6.0883144468069075</td>\n",
       "      <td>5.834850</td>\n",
       "      <td>6.088314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Epoch: 44/50</td>\n",
       "      <td>Loss: 5.827017261135962</td>\n",
       "      <td>Val: 6.097826967140039</td>\n",
       "      <td>5.827017</td>\n",
       "      <td>6.097827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epoch_info                       Loss                Validation  \\\n",
       "0    Epoch: 1/50   Loss: 10.173321262482673    Val: 7.458063776294391   \n",
       "1    Epoch: 2/50    Loss: 7.410941631563248    Val: 7.286813758313656   \n",
       "2    Epoch: 3/50    Loss: 7.008255389428908    Val: 7.037418337663015   \n",
       "3    Epoch: 4/50   Loss: 6.7039098278168705    Val: 6.626706438014905   \n",
       "4    Epoch: 5/50    Loss: 6.533476629564839    Val: 7.827299116551876   \n",
       "5    Epoch: 6/50    Loss: 6.492760673646004    Val: 6.769813926517964   \n",
       "6    Epoch: 7/50    Loss: 6.339594133438602    Val: 9.035120700796446   \n",
       "7    Epoch: 8/50    Loss: 6.326135927631009    Val: 6.680800733466943   \n",
       "8    Epoch: 9/50    Loss: 6.332643908839072    Val: 6.456798662990332   \n",
       "9   Epoch: 10/50    Loss: 6.215676646078786    Val: 6.635956634581089   \n",
       "10  Epoch: 11/50    Loss: 6.199374475786763     Val: 6.22813256730636   \n",
       "11  Epoch: 12/50     Loss: 6.19963284461729    Val: 6.362288365761439   \n",
       "12  Epoch: 13/50    Loss: 6.164883244422175    Val: 6.407494433969259   \n",
       "13  Epoch: 14/50     Loss: 6.14712978178455    Val: 6.433090079327425   \n",
       "14  Epoch: 15/50    Loss: 6.162849318596624     Val: 6.45341512610515   \n",
       "15  Epoch: 16/50    Loss: 6.103065859886907    Val: 5.977973246077696   \n",
       "16  Epoch: 17/50    Loss: 6.067870832258655    Val: 6.570273294051488   \n",
       "17  Epoch: 18/50   Loss: 6.0905032465534825    Val: 5.882647534708182   \n",
       "18  Epoch: 19/50    Loss: 6.107838707585489     Val: 5.96731440226237   \n",
       "19  Epoch: 20/50    Loss: 6.064329224248087    Val: 6.141708275675773   \n",
       "20  Epoch: 21/50    Loss: 6.057978860793575      Val: 6.2946148549517   \n",
       "21  Epoch: 22/50    Loss: 6.046493253400249    Val: 6.225412599245707   \n",
       "22  Epoch: 23/50   Loss: 5.9677022195631455    Val: 7.275475724538167   \n",
       "23  Epoch: 24/50    Loss: 6.068731338747086    Val: 6.109281359612941   \n",
       "24  Epoch: 25/50    Loss: 5.913550269219183   Val: 6.0394425248106325   \n",
       "25  Epoch: 26/50    Loss: 5.866663963563981    Val: 6.134553797046343   \n",
       "26  Epoch: 27/50    Loss: 5.844537611930601    Val: 6.101148352026939   \n",
       "27  Epoch: 28/50    Loss: 5.858050346374512    Val: 6.128651245435079   \n",
       "28  Epoch: 29/50    Loss: 5.855190707791236   Val: 6.0957833970586455   \n",
       "29  Epoch: 30/50   Loss: 5.8122999283575245   Val: 6.1085436602433525   \n",
       "30  Epoch: 31/50   Loss: 5.8056469425078365    Val: 6.077391090989113   \n",
       "31  Epoch: 32/50    Loss: 5.816736698150635     Val: 6.08585768888394   \n",
       "32  Epoch: 33/50    Loss: 5.816037516440114    Val: 6.083798488477866   \n",
       "33  Epoch: 34/50    Loss: 5.847229772998441    Val: 6.083370262384415   \n",
       "34  Epoch: 35/50    Loss: 5.799741975722775    Val: 6.086282580594221   \n",
       "35  Epoch: 36/50    Loss: 5.841159128373669     Val: 6.07359539270401   \n",
       "36  Epoch: 37/50    Loss: 5.817716398546772    Val: 6.087334063152472   \n",
       "37  Epoch: 38/50    Loss: 5.826847645544237    Val: 6.085816042125225   \n",
       "38  Epoch: 39/50    Loss: 5.775268385487218    Val: 6.095939626793067   \n",
       "39  Epoch: 40/50    Loss: 5.788922725185271    Val: 6.084656250476837   \n",
       "40  Epoch: 41/50   Loss: 5.7999827938695105    Val: 6.101407463351886   \n",
       "41  Epoch: 42/50    Loss: 5.833145203128938    Val: 6.082753171026707   \n",
       "42  Epoch: 43/50    Loss: 5.834849803678451   Val: 6.0883144468069075   \n",
       "43  Epoch: 44/50    Loss: 5.827017261135962    Val: 6.097826967140039   \n",
       "\n",
       "         loss       val  \n",
       "0   10.173321  7.458064  \n",
       "1    7.410942  7.286814  \n",
       "2    7.008255  7.037418  \n",
       "3    6.703910  6.626706  \n",
       "4    6.533477  7.827299  \n",
       "5    6.492761  6.769814  \n",
       "6    6.339594  9.035121  \n",
       "7    6.326136  6.680801  \n",
       "8    6.332644  6.456799  \n",
       "9    6.215677  6.635957  \n",
       "10   6.199374  6.228133  \n",
       "11   6.199633  6.362288  \n",
       "12   6.164883  6.407494  \n",
       "13   6.147130  6.433090  \n",
       "14   6.162849  6.453415  \n",
       "15   6.103066  5.977973  \n",
       "16   6.067871  6.570273  \n",
       "17   6.090503  5.882648  \n",
       "18   6.107839  5.967314  \n",
       "19   6.064329  6.141708  \n",
       "20   6.057979  6.294615  \n",
       "21   6.046493  6.225413  \n",
       "22   5.967702  7.275476  \n",
       "23   6.068731  6.109281  \n",
       "24   5.913550  6.039443  \n",
       "25   5.866664  6.134554  \n",
       "26   5.844538  6.101148  \n",
       "27   5.858050  6.128651  \n",
       "28   5.855191  6.095783  \n",
       "29   5.812300  6.108544  \n",
       "30   5.805647  6.077391  \n",
       "31   5.816737  6.085858  \n",
       "32   5.816038  6.083798  \n",
       "33   5.847230  6.083370  \n",
       "34   5.799742  6.086283  \n",
       "35   5.841159  6.073595  \n",
       "36   5.817716  6.087334  \n",
       "37   5.826848  6.085816  \n",
       "38   5.775268  6.095940  \n",
       "39   5.788923  6.084656  \n",
       "40   5.799983  6.101407  \n",
       "41   5.833145  6.082753  \n",
       "42   5.834850  6.088314  \n",
       "43   5.827017  6.097827  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(loss_file_path, sep=',')\n",
    "df = pd.read_csv(loss_file_path, header=None, sep=\",\", names=[\"Epoch_info\", \"Loss\", \"Validation\"])\n",
    "\n",
    "df = df.dropna()\n",
    "df['loss'] = df['Loss'].str.split(':').str[-1].astype(float)\n",
    "df['val'] = df['Validation'].str.split(':').str[-1].astype(float)\n",
    "\n",
    "df = df.reset_index().drop(columns=['index'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df.val < 100]\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, df.loss, label='Training Loss')\n",
    "plt.plot(df.index, df.val, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.ylim(7, 20)\n",
    "plt.title(f'Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch_info                       Loss               Validation       loss  \\\n",
      "0  Epoch: 1/50   Loss: 10.173321262482673   Val: 7.458063776294391  10.173321   \n",
      "\n",
      "        val  \n",
      "0  7.458064         Epoch_info                       Loss               Validation  \\\n",
      "17  Epoch: 18/50   Loss: 6.0905032465534825   Val: 5.882647534708182   \n",
      "\n",
      "        loss       val  \n",
      "17  6.090503  5.882648  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_loss_min = df[df.Loss == df.Loss.min()]\n",
    "df_val_min = df[df.val == df.val.min()]\n",
    "print(df_loss_min,df_val_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# # Path to the loss file\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[32, 64, 128].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/256_1ctP_0.0001_[32, 64, 128].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[8, 16, 32].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[8, 16, 32].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[16, 32, 64].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[16, 32, 64, 128].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(4).txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_1e-05_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_[32, 64, 128, 256]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.001_[8, 16, 32].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.001_[8, 16, 32]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_[8, 16, 32]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_[16, 32, 64]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_[16, 32, 64, 128]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_[16, 32, 64, 128, 256]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.01_[16, 32, 64, 128, 256]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_1e-05_[16, 32, 64, 128, 256]_L1L2(6).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_1e-05_[32, 64, 128, 256, 512]_L1L2(6).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_opt/128_1optP_0.0001_CNN4_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_CT/cnn4_128_0.01_5_16.txt'\n",
    "\n",
    "\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# # Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f/128_1optP_0.0001_CNN6_L1L2(6).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f/128_1optP_1e-05_CNN6_L1L2(6).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f/128_1optP_0.0001_CNN6_L1L2(5).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f/128_1optP_0.0001_CNN6_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.01_[16, 32, 64].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.01_[16, 32, 64, 128].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.0001_[16, 32, 64, 128].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(4).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_1e-05_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_3f_1ct/128_1ctP_0.0001_[32, 64, 128, 256]_L1L2(4).txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        # match_epoch = re.search(r'Epoch: (\\d+)/\\d+, *Loss: (\\d+\\.\\d+), *Val Loss: (\\d+\\.\\d+)', line)\n",
    "\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "\n",
    "# Set the background color inside the plot area\n",
    "plt.gca().set_facecolor('lightgrey')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_oneone/128_11P_0.0001_[32, 64, 128].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_oneone/128_11P_0.0001_[32, 64, 128, 256].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_oneone/128_11P_1e-05_[16, 32, 64, 128].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_oneone/128_11P_0.0001_[16, 32, 64, 128].txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG_oneone/128_11P_0.01_[16, 32, 64, 128].txt'\n",
    "\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[8, 16, 32].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[16, 32, 64].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.01_[16, 32, 64, 128].txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(4).txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_0.0001_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/128_1ctP_1e-05_[16, 32, 64, 128]_L1L2(5).txt'\n",
    "\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.gca().set_facecolor('lavender')\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all.txt'\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all_opt.txt'\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all_opt_simplemodel.txt'\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all_opt_simplemodel_newsortdatabiggerlr.txt'\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the loss file\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all_opt_deepermodel.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_all2_opt_deepermodel.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_morepatient.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_morepatient_optuna.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_morepatient_optuna2.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_morepatient2.txt'\n",
    "loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_1rCT.txt'\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "with open(loss_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match_epoch = re.search(r'Epoch: (\\d+)/\\d+, Loss: (\\d+\\.\\d+), Val: (\\d+\\.\\d+)', line)\n",
    "        if match_epoch:\n",
    "            epochs.append(int(match_epoch.group(1)))\n",
    "            training_losses.append(float(match_epoch.group(2)))\n",
    "            validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Training Losses:\", training_losses)\n",
    "print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, training_losses, label='Training Loss')\n",
    "plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import re\n",
    "\n",
    "# # Path to the loss file\n",
    "# # loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/dg.txt'\n",
    "# loss_file_path ='/home/shahpouriz/Data/DBP_Project/LOG/loss_Model_3f_newopt.txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/loss_Model_3f_newopt_morebatches.txt'\n",
    "# loss_file_path = '/home/shahpouriz/Data/DBP_Project/LOG/loss_128_lessp.txt'\n",
    "\n",
    "# epochs = []\n",
    "# training_losses = []\n",
    "# validation_losses = []\n",
    "\n",
    "# # Open the loss file and read the lines\n",
    "# with open(loss_file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Adjust the regex pattern to match the file's format\n",
    "#         # The regex now allows for optional spaces around the commas\n",
    "#         match_epoch = re.search(r'Epoch: (\\d+)/\\d+, *Loss: (\\d+\\.\\d+), *Val Loss: (\\d+\\.\\d+)', line)\n",
    "#         if match_epoch:\n",
    "#             epochs.append(int(match_epoch.group(1)))\n",
    "#             training_losses.append(float(match_epoch.group(2)))\n",
    "#             validation_losses.append(float(match_epoch.group(3)))\n",
    "\n",
    "# print(\"Epochs:\", epochs)\n",
    "# print(\"Training Losses:\", training_losses)\n",
    "# print(\"Validation Losses:\", validation_losses)\n",
    "\n",
    "# # Plot the losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, training_losses, label='Training Loss')\n",
    "# plt.plot(epochs, validation_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Losses')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import list_patient_folders, prepare_data_nrrd, split_data\n",
    "\n",
    "# Specify the directory where the patient folders are located\n",
    "# data_path_NEW = '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/proton'\n",
    "# data_path_OLD = '/home/shahpouriz/Data/DBP_oldDATA/nrrd/proton'\n",
    "data_path_OLD = '/home/shahpouriz/Data/DBP_oldDATA/nrrd/test'\n",
    "data_path_NEW = '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test'\n",
    "\n",
    "# Get the list of patient folders\n",
    "\n",
    "patient_list_NEW = list_patient_folders(data_path_NEW)\n",
    "pct, rct, pos = prepare_data_nrrd(data_path_NEW, patient_list_NEW)\n",
    "data_NEW = [{\"plan\": img[0], \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(pct, rct, pos)]\n",
    "\n",
    "\n",
    "patient_list_OLD = list_patient_folders(data_path_OLD)\n",
    "pct, rct, pos = prepare_data_nrrd(data_path_OLD, patient_list_OLD)\n",
    "data_OLD = [{\"plan\": img[0], \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(pct, rct, pos)]\n",
    "\n",
    "\n",
    "# Assuming data_NEW and data_OLD are your lists of dictionaries\n",
    "data = data_NEW + data_OLD\n",
    "# data = data_NEW[:20] + data_OLD[:20]\n",
    "\n",
    "# Split the data\n",
    "_, val_data, test_data = split_data(data)\n",
    "\n",
    "# Check the lengths of the sets\n",
    "# print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(val_data))\n",
    "print(\"Number of test samples:\", len(test_data))\n",
    "\n",
    "# train_files, val_files = data_dicts[:18], data_dicts[18:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### My method\n",
    "\n",
    "from monai.transforms import Compose, LoadImaged, ScaleIntensityd, EnsureChannelFirstd, Spacingd, SpatialPadd, CenterSpatialCropd, ScaleIntensityRanged\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.transforms import LoadImaged\n",
    "from monai.data.image_reader import ITKReader\n",
    "\n",
    "dim = 128\n",
    "pixdim = (2.0, 2.0, 2.0)\n",
    "size = (dim, dim, dim)\n",
    "transforms = Compose([\n",
    "        LoadImaged(keys=[\"plan\", \"repeat\"], reader=ITKReader()),\n",
    "        \n",
    "        EnsureChannelFirstd(keys=[\"plan\", \"repeat\"]),\n",
    "        ScaleIntensityd(keys=[\"plan\", \"repeat\"]),\n",
    "        Spacingd(keys=[\"plan\", \"repeat\"], pixdim=pixdim, mode='trilinear'),\n",
    "        SpatialPadd(keys=[\"plan\", \"repeat\"], spatial_size=size, mode='constant'),  # Ensure minimum size\n",
    "        CenterSpatialCropd(keys=[\"plan\", \"repeat\"], roi_size=size),  # Ensure uniform size\n",
    "    ])\n",
    "\n",
    "\n",
    "val_ds = CacheDataset(data=val_data, transform=transforms, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "test_ds = CacheDataset(data=test_data, transform=transforms, cache_rate=1.0, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dual_network import Dual3DCNN6 as Dual\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "saved_model_path = '/home/shahpouriz/Data/DBP_Project/LOG/model_128_5.pt'\n",
    "# saved_model_path = '/home/shahpouriz/Data/DBP_Project/LOG/loss_simple_Model_256_mse_7.pt'\n",
    "\n",
    "model = Dual(width=dim, height=dim, depth=dim)  # Assuming the model architecture is Dual\n",
    "model.load_state_dict(torch.load(saved_model_path))\n",
    "model.to(device)  # Make sure to move the model to the appropriate device (CPU or GPU)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "import torch\n",
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "# Assuming `test_loader` is your DataLoader for the test set\n",
    "model.eval()  # Set model to evaluation mode\n",
    "total_mae = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients\n",
    "    for batch_data in test_loader:\n",
    "        # Load data and model predictions\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Assuming 'pos' is your ground truth\n",
    "        \n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        \n",
    "        # Calculate MAE between output and ground truth\n",
    "        mae = torch.abs(output_test - reg_test).mean()\n",
    "        total_mae += mae.item() * pCT_test.size(0)  # Multiply by batch size for correct average\n",
    "        total_samples += pCT_test.size(0)\n",
    "    \n",
    "    # Calculate average MAE across all test samples\n",
    "    average_mae = total_mae / total_samples\n",
    "    print(f\"Average MAE on Test Set: {average_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "mae_values = []  # List to store individual MAE values\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients\n",
    "    for batch_data in test_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "        \n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        \n",
    "        # Calculate MAE for each item in the batch and store it\n",
    "        mae = torch.abs(output_test - reg_test).mean(dim=1)  # Calculate MAE for each sample\n",
    "        mae_values.extend(mae.cpu().numpy())  # Store the MAE values\n",
    "\n",
    "# Plotting the histogram of MAE values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(mae_values, bins=30, color='skyblue')\n",
    "plt.title('Histogram of MAE Values on Test Set')\n",
    "plt.xlabel('Mean Absolute Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "mae_values_x, mae_values_y, mae_values_z = [], [], []  # Lists to store individual MAE values for each axis\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients\n",
    "    for batch_data in test_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "        \n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        \n",
    "        # Calculate MAE for each axis and store it\n",
    "        mae_x = torch.abs(output_test[:, 0] - reg_test[:, 0])  # MAE for x axis\n",
    "        mae_y = torch.abs(output_test[:, 1] - reg_test[:, 1])  # MAE for y axis\n",
    "        mae_z = torch.abs(output_test[:, 2] - reg_test[:, 2])  # MAE for z axis\n",
    "        \n",
    "        mae_values_x.extend(mae_x.cpu().numpy())\n",
    "        mae_values_y.extend(mae_y.cpu().numpy())\n",
    "        mae_values_z.extend(mae_z.cpu().numpy())\n",
    "\n",
    "# Plotting the histogram of MAE values for each axis\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(mae_values_x, bins=30, color='skyblue')\n",
    "plt.title('Histogram of MAE Values on X Axis')\n",
    "plt.xlabel('Mean Absolute Error (mm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(mae_values_y, bins=30, color='skyblue')\n",
    "plt.title('Histogram of MAE Values on Y Axis')\n",
    "plt.xlabel('Mean Absolute Error (mm)')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(mae_values_z, bins=30, color='skyblue')\n",
    "plt.title('Histogram of MAE Values on Z Axis')\n",
    "plt.xlabel('Mean Absolute Error (mm)')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# # Set model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Lists to store MAE and MSE values for each axis\n",
    "# mae_values_x, mae_values_y, mae_values_z = [], [], []\n",
    "# mse_values_x, mse_values_y, mse_values_z = [], [], []\n",
    "\n",
    "# with torch.no_grad():  # Disable gradients for efficiency\n",
    "#     for batch_data in test_loader:\n",
    "#         pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "#         reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "#         output_test = model(pCT_test, rCT_test)\n",
    "\n",
    "#         # Calculate MAE and MSE for each axis\n",
    "#         mae_x = torch.abs(output_test[:, 0] - reg_test[:, 0])\n",
    "#         mae_y = torch.abs(output_test[:, 1] - reg_test[:, 1])\n",
    "#         mae_z = torch.abs(output_test[:, 2] - reg_test[:, 2])\n",
    "        \n",
    "#         mse_x = (output_test[:, 0] - reg_test[:, 0]) ** 2\n",
    "#         mse_y = (output_test[:, 1] - reg_test[:, 1]) ** 2\n",
    "#         mse_z = (output_test[:, 2] - reg_test[:, 2]) ** 2\n",
    "\n",
    "#         # Append to lists\n",
    "#         mae_values_x.extend(mae_x.cpu().numpy())\n",
    "#         mae_values_y.extend(mae_y.cpu().numpy())\n",
    "#         mae_values_z.extend(mae_z.cpu().numpy())\n",
    "\n",
    "#         mse_values_x.extend(mse_x.cpu().numpy())\n",
    "#         mse_values_y.extend(mse_y.cpu().numpy())\n",
    "#         mse_values_z.extend(mse_z.cpu().numpy())\n",
    "\n",
    "# # Function to plot histograms\n",
    "# def plot_histogram(values, title, xlabel, ylabel='Frequency', color='indigo' ):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(values, bins=30, color=color, alpha=0.7)\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(xlabel)\n",
    "#     plt.ylabel(ylabel)\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.show()\n",
    "\n",
    "# # Plotting the histograms\n",
    "# plot_histogram(mae_values_x, 'Histogram of MAE Values on Test Set - X Axis', 'Mean Absolute Error')\n",
    "# plot_histogram(mae_values_y, 'Histogram of MAE Values on Test Set - Y Axis', 'Mean Absolute Error')\n",
    "# plot_histogram(mae_values_z, 'Histogram of MAE Values on Test Set - Z Axis', 'Mean Absolute Error')\n",
    "\n",
    "# plot_histogram(mse_values_x, 'Histogram of MSE Values on Test Set - X Axis', 'Mean Squared Error', color='darkcyan')\n",
    "# plot_histogram(mse_values_y, 'Histogram of MSE Values on Test Set - Y Axis', 'Mean Squared Error', color='darkcyan')\n",
    "# plot_histogram(mse_values_z, 'Histogram of MSE Values on Test Set - Z Axis', 'Mean Squared Error', color='darkcyan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "\n",
    "# Setup\n",
    "model.eval()  # Evaluation mode\n",
    "mae_x, mae_y, mae_z = [], [], []  # Lists to store MAE for each axis\n",
    "mse_x, mse_y, mse_z = [], [], []  # Lists to store MSE for each axis\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in test_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)\n",
    "\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "\n",
    "        # Calculate MAE and MSE for each axis and store\n",
    "        mae_values = torch.abs(output_test - reg_test)\n",
    "        mse_values = (output_test - reg_test) ** 2\n",
    "        \n",
    "        mae_x.extend(mae_values[:, 0].cpu().numpy())\n",
    "        mae_y.extend(mae_values[:, 1].cpu().numpy())\n",
    "        mae_z.extend(mae_values[:, 2].cpu().numpy())\n",
    "        \n",
    "        mse_x.extend(mse_values[:, 0].cpu().numpy())\n",
    "        mse_y.extend(mse_values[:, 1].cpu().numpy())\n",
    "        mse_z.extend(mse_values[:, 2].cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12), constrained_layout=True)\n",
    "fig.suptitle('Distribution of MAE and MSE by Axis')\n",
    "\n",
    "# Define histogram plotting function\n",
    "def plot_histogram(ax, data, title, color):\n",
    "    ax.hist(data, bins=30, color=color, alpha=0.7)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Error Value (mm)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# MAE histograms\n",
    "plot_histogram(axs[0, 0], mae_x, 'MAE X Axis', 'indigo')\n",
    "plot_histogram(axs[0, 1], mae_y, 'MAE Y Axis', 'indigo')\n",
    "plot_histogram(axs[0, 2], mae_z, 'MAE Z Axis', 'indigo')\n",
    "\n",
    "# MSE histograms\n",
    "plot_histogram(axs[1, 0], mse_x, 'MSE X Axis', 'darkcyan')\n",
    "plot_histogram(axs[1, 1], mse_y, 'MSE Y Axis', 'darkcyan')\n",
    "plot_histogram(axs[1, 2], mse_z, 'MSE Z Axis', 'darkcyan')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import mse_loss, l1_loss  # l1_loss is MAE\n",
    "\n",
    "# Assuming `test_loader` and `model` are already defined\n",
    "model.eval()  # Set model to evaluation mode\n",
    "total_mae = 0.0\n",
    "total_mse = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for batch_data in test_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = l1_loss(output_test, reg_test, reduction='sum')  # Summing to calculate total MAE later\n",
    "        total_mae += mae.item()\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = mse_loss(output_test, reg_test, reduction='sum')  # Summing to calculate total MSE later\n",
    "        total_mse += mse.item()\n",
    "\n",
    "        total_samples += pCT_test.size(0)\n",
    "    \n",
    "    # Calculate average MAE and MSE across all test samples\n",
    "    average_mae = total_mae / total_samples\n",
    "    average_mse = total_mse / total_samples\n",
    "    print(f\"Average MAE on Test Set: {average_mae}\")\n",
    "    print(f\"Average MSE on Test Set: {average_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "total_distance = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for batch_data in test_loader:\n",
    "        # Load data\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "        \n",
    "        # Model prediction\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        # print(output_test)\n",
    "        # Calculate Euclidean distance between output and ground truth\n",
    "        distance = torch.sqrt(torch.sum((output_test - reg_test) ** 2, dim=1))\n",
    "        total_distance += distance.sum().item()\n",
    "        total_samples += distance.size(0)\n",
    "    \n",
    "    # Calculate average distance across all test samples\n",
    "    average_distance = total_distance / total_samples\n",
    "    print(f\"Average Euclidean Distance on Test Set: {average_distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "total_distance_x = 0.0\n",
    "total_distance_y = 0.0\n",
    "total_distance_z = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for batch_data in test_loader:\n",
    "        # Load test data\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "        \n",
    "        # Get model predictions\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        \n",
    "        # Calculate Euclidean distance for each axis separately\n",
    "        distance_x = torch.abs(output_test[:, 0] - reg_test[:, 0])\n",
    "        distance_y = torch.abs(output_test[:, 1] - reg_test[:, 1])\n",
    "        distance_z = torch.abs(output_test[:, 2] - reg_test[:, 2])\n",
    "        \n",
    "        total_distance_x += distance_x.sum().item()\n",
    "        total_distance_y += distance_y.sum().item()\n",
    "        total_distance_z += distance_z.sum().item()\n",
    "        total_samples += distance_x.size(0)  # Assuming batch size is consistent across all dimensions\n",
    "    \n",
    "    # Calculate average distance for each axis across all test samples\n",
    "    average_distance_x = total_distance_x / total_samples\n",
    "    average_distance_y = total_distance_y / total_samples\n",
    "    average_distance_z = total_distance_z / total_samples\n",
    "    print(f\"Average Distance on Test Set - X Axis: {average_distance_x}\")\n",
    "    print(f\"Average Distance on Test Set - Y Axis: {average_distance_y}\")\n",
    "    print(f\"Average Distance on Test Set - Z Axis: {average_distance_z}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = []\n",
    "with torch.no_grad():\n",
    "    for batch_data in val_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].clone().detach().requires_grad_(True).to(device)  # If gradients are required for 'reg'\n",
    "\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "        loss_test = mae_loss(output_test, reg_test)\n",
    "\n",
    "        test_loss.append(loss_test.item())\n",
    "\n",
    "mean_test_loss = np.mean(test_loss)\n",
    "print(f'Loss for validation set: {mean_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Initialize accumulators\n",
    "distances_x = []\n",
    "distances_y = []\n",
    "distances_z = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # No need for gradient computation\n",
    "    for batch_data in test_loader:\n",
    "        pCT_test, rCT_test = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg_test = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "\n",
    "        output_test = model(pCT_test, rCT_test)\n",
    "\n",
    "        # Compute absolute differences for each axis\n",
    "        distance_x = torch.abs(output_test[:, 0] - reg_test[:, 0])\n",
    "        distance_y = torch.abs(output_test[:, 1] - reg_test[:, 1])\n",
    "        distance_z = torch.abs(output_test[:, 2] - reg_test[:, 2])\n",
    "\n",
    "        # Collect distances\n",
    "        distances_x.extend(distance_x.cpu().numpy())\n",
    "        distances_y.extend(distance_y.cpu().numpy())\n",
    "        distances_z.extend(distance_z.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for statistical analysis\n",
    "distances_x = np.array(distances_x)\n",
    "distances_y = np.array(distances_y)\n",
    "distances_z = np.array(distances_z)\n",
    "\n",
    "# Calculate mean and standard deviation for each axis\n",
    "mean_x, sigma_x = np.mean(distances_x), np.std(distances_x)\n",
    "mean_y, sigma_y = np.mean(distances_y), np.std(distances_y)\n",
    "mean_z, sigma_z = np.mean(distances_z), np.std(distances_z)\n",
    "\n",
    "# Print results\n",
    "print(f\"X Axis: Mean = {mean_x:.2f}, Sigma = {sigma_x:.2f}, Range = Mean ± Sigma = [{mean_x-sigma_x:.2f}, {mean_x+sigma_x:.2f}]\")\n",
    "print(f\"Y Axis: Mean = {mean_y:.2f}, Sigma = {sigma_y:.2f}, Range = Mean ± Sigma = [{mean_y-sigma_y:.2f}, {mean_y+sigma_y:.2f}]\")\n",
    "print(f\"Z Axis: Mean = {mean_z:.2f}, Sigma = {sigma_z:.2f}, Range = Mean ± Sigma = [{mean_z-sigma_z:.2f}, {mean_z+sigma_z:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming distances_x, distances_y, distances_z are numpy arrays from the previous step\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "data = {\n",
    "    'X Axis': distances_x,\n",
    "    'Y Axis': distances_y,\n",
    "    'Z Axis': distances_z\n",
    "}\n",
    "df_distances = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame to long-format for seaborn\n",
    "df_long = pd.melt(df_distances, var_name='Axis', value_name='Distance')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(4, 5))\n",
    "sns.boxplot(x='Axis', y='Distance', data=df_long, palette='viridis', showfliers=True)\n",
    "plt.title('Distribution of Distances by Axis')\n",
    "plt.ylabel('Distance (mm)')\n",
    "plt.xlabel('Axises')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# Accumulate all ground truth and predictions for plotting\n",
    "all_gt = []  # For storing all ground truth coordinates\n",
    "all_pred = []  # For storing all prediction coordinates\n",
    "\n",
    "model.eval()  # Ensure model is in evaluation mode\n",
    "with torch.no_grad():  # No gradients needed\n",
    "    for batch_data in test_loader:\n",
    "        pCT, rCT = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "        reg = batch_data[\"pos\"].to(device)  # Ground truth coordinates\n",
    "        \n",
    "        output = model(pCT, rCT)  # Model predictions\n",
    "        \n",
    "        # Collect coordinates\n",
    "        all_gt.append(reg.cpu().numpy())\n",
    "        all_pred.append(output.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_gt = np.concatenate(all_gt) \n",
    "all_pred = np.concatenate(all_pred)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming all_gt and all_pred are already defined and populated\n",
    "\n",
    "# # Creating a 3D scatter plot with emphasis on all points\n",
    "# fig = plt.figure(figsize=(12, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Ground truth coordinates in blue, with slightly larger marker size\n",
    "# ax.scatter(all_gt[:, 0]/1000, all_gt[:, 1]/1000, all_gt[:, 2]/1000, color='blue', alpha=0.6, edgecolor='w', s=50, label='Ground Truth')\n",
    "\n",
    "# # Predicted coordinates in orange, with slightly larger marker size\n",
    "# ax.scatter(all_pred[:, 0], all_pred[:, 1], all_pred[:, 2], color='orange', alpha=1.0, edgecolor='w', s=50, label='Prediction')\n",
    "\n",
    "# # Labeling axes\n",
    "# ax.set_xlabel('X Axis')\n",
    "# ax.set_ylabel('Y Axis')\n",
    "# ax.set_zlabel('Z Axis')\n",
    "# ax.set_title('3D Scatter Plot of Ground Truth and Predicted Coordinates')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from monai.transforms import LoadImaged\n",
    "# from monai.data.image_reader import ITKReader\n",
    "\n",
    "# load_image = LoadImaged(keys=[\"plan\", \"repeat\"], reader=ITKReader())\n",
    "# sample_data = test_data[0]  \n",
    "\n",
    "# sample_data = load_image(sample_data)\n",
    "# pCT = sample_data[\"plan\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "# rCT = sample_data[\"repeat\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "# ground_truth = sample_data[\"pos\"]\n",
    "# print(\"Ground Truth:\", ground_truth)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     prediction = model(pCT, rCT)\n",
    "# prediction = prediction[0].cpu().numpy()\n",
    "# print(\"Coordination predicted by model:\", prediction)\n",
    "\n",
    "# # Plot ground truth and predictions\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(ground_truth[0], ground_truth[1], ground_truth[2], c='r', marker='o', label='Ground Truth')\n",
    "# ax.scatter(prediction[0], prediction[1], prediction[2], c='b', marker='x', label='Predictions')\n",
    "\n",
    "# ax.set_title('Comparison Before and After Training')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from monai.transforms import LoadImaged\n",
    "# from monai.data.image_reader import ITKReader\n",
    "\n",
    "# # Function to plot ground truth and predictions\n",
    "# def plot_samples(test_files, model, device):\n",
    "#     all_ground_truth = []\n",
    "#     all_predictions = []\n",
    "\n",
    "#     for sample_data in test_files:\n",
    "#         sample_data = load_image(sample_data)\n",
    "#         pCT = sample_data[\"plan\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "#         rCT = sample_data[\"repeat\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "#         ground_truth = sample_data[\"pos\"]\n",
    "        \n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             prediction = model(pCT, rCT)\n",
    "#         prediction = prediction[0].cpu().numpy()\n",
    "        \n",
    "\n",
    "#         all_ground_truth.append(ground_truth)\n",
    "#         all_predictions.append(prediction)\n",
    "\n",
    "#     # Plot all ground truth and predictions in a single 3D plot\n",
    "#     fig = plt.figure(figsize=(10, 5))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     # Scatter plot for ground truth\n",
    "#     all_ground_truth = np.array(all_ground_truth)\n",
    "#     # print(all_ground_truth)\n",
    "#     ax.scatter(all_ground_truth[:, 0], all_ground_truth[:, 1], all_ground_truth[:, 2], c='r', alpha = 0.5, label='Ground Truth')\n",
    "\n",
    "#     # Scatter plot for predictions\n",
    "#     all_predictions = np.array(all_predictions)\n",
    "#     ax.scatter(all_predictions[:, 0]/100, all_predictions[:, 1]/100, all_predictions[:, 2]/100, c='b', marker='x', label='Predictions')\n",
    "\n",
    "#     ax.set_title('Coordinations')\n",
    "#     ax.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Plot all ground truth and predictions in a single 3D plot\n",
    "# plot_samples(test_data, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from monai.transforms import LoadImaged\n",
    "# from monai.data.image_reader import ITKReader\n",
    "\n",
    "# # Lists to store differences for each coordinate\n",
    "# x_diffs, y_diffs, z_diffs = [], [], []\n",
    "\n",
    "# # Iterate through all test samples\n",
    "# for sample_data in test_data:\n",
    "#     load_image = LoadImaged(keys=[\"plan\", \"repeat\"], reader=ITKReader())\n",
    "#     sample_data = load_image(sample_data)\n",
    "\n",
    "#     pCT = sample_data[\"plan\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "#     rCT = sample_data[\"repeat\"].unsqueeze(0).unsqueeze(0).to(device)\n",
    "#     ground_truth = sample_data[\"pos\"]\n",
    "    \n",
    "#     # Get the model prediction\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         prediction = model(pCT, rCT)\n",
    "#         prediction = prediction[0].cpu().numpy()\n",
    "\n",
    "#         # Calculate differences\n",
    "#         x_diff = np.abs(ground_truth[0] - prediction[0])\n",
    "#         y_diff = np.abs(ground_truth[1] - prediction[1])\n",
    "#         z_diff = np.abs(ground_truth[2] - prediction[2])\n",
    "\n",
    "#         # Append differences to the lists\n",
    "#         x_diffs.append(x_diff)\n",
    "#         y_diffs.append(y_diff)\n",
    "#         z_diffs.append(z_diff)\n",
    "\n",
    "# # Create box plots\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# axes[0].boxplot(x_diffs, labels=['X'])\n",
    "# axes[0].set_title('X Coordinate Differences')\n",
    "\n",
    "# axes[1].boxplot(y_diffs, labels=['Y'])\n",
    "# axes[1].set_title('Y Coordinate Differences')\n",
    "\n",
    "# axes[2].boxplot(z_diffs, labels=['Z'])\n",
    "# axes[2].set_title('Z Coordinate Differences')\n",
    "\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
