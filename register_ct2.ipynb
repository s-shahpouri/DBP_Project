{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from CT import construct_CT_object\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_path_structures_DICOM_file(path_CT_DICOM_series):\n",
    "    filenames = [filename for filename in os.listdir(path_CT_DICOM_series) if filename.startswith('RS')]\n",
    "    print(filenames)\n",
    "\n",
    "    assert len(filenames) > 0, \"no structures DICOM file found\"\n",
    "    assert len(filenames) <= 1, \"more than one structures DICOM files found\"\n",
    "\n",
    "    return os.path.join(path_CT_DICOM_series, filenames[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# root_patient = \"/data/oosterhoff/patients/DBP_OP007/\"\n",
    "# name_fixed_CT = 'pCTp0'\n",
    "# name_moving_CT = 'rCTp12'\n",
    "\n",
    "# path_fixed_CT = os.path.join(root_patient, name_fixed_CT, '')\n",
    "# path_moving_CT = os.path.join(root_patient, name_moving_CT, '')\n",
    "\n",
    "\n",
    "# path_struct_fixed_CT = get_path_structures_DICOM_file(path_fixed_CT)\n",
    "# path_struct_moving_CT = get_path_structures_DICOM_file(path_moving_CT)\n",
    "\n",
    "\n",
    "\n",
    "# fixed_CT = construct_CT_object(name_fixed_CT, path_fixed_CT, path_struct_fixed_CT, roi_names = ['External'])\n",
    "# moving_CT = construct_CT_object(name_moving_CT, path_moving_CT, path_struct_moving_CT, roi_names = ['External'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import SimpleITK as sitk\n",
    "# fixed_CT_array = sitk.GetArrayFromImage(fixed_CT.image)\n",
    "# moving_CT_array = sitk.GetArrayFromImage(moving_CT.image)\n",
    "# plt.imshow(fixed_CT_array[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "class CaseDataReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        \n",
    "        self.id = self.data['patient_id']\n",
    "        \n",
    "        self.examinations_transformations = self.extract_details()\n",
    "\n",
    "\n",
    "\n",
    "    # def new_transfer_param(self, rigid_matrix):\n",
    "    #     max_translation = 1.5\n",
    "    #     num_samples = 5  # Number of random coordinates to generate\n",
    "    #     final_translation_coordinate = {'x': [], 'y': [], 'z': []}  # Initialize the dictionary with lists\n",
    "        \n",
    "    #     matrix = list(rigid_matrix)  # Initialize the matrix outside the loop\n",
    "    #     for _ in range(num_samples):\n",
    "    #         for idx, key in zip([3, 7, 11], ['x', 'y', 'z']):\n",
    "    #             random_translation = (2 * random.random() - 1) * max_translation\n",
    "    #             matrix[idx] += random_translation * 10  # Apply translation and convert to mm\n",
    "    #             final_translation_coordinate[key].append(random_translation * 10)  # Store each translation in mm in the list\n",
    "        \n",
    "    #     return matrix, final_translation_coordinate\n",
    "\n",
    "    def new_transfer_param(self, rigid_matrix):\n",
    "        max_translation = 1.5\n",
    "        num_samples = 5  # Number of random coordinates to generate\n",
    "        \n",
    "        final_translation_coordinate = {}  # Dictionary to hold all options\n",
    "        new_matrix = {}\n",
    "        matrix_base = list(rigid_matrix)  # Copy base matrix to modify for each sample\n",
    "        \n",
    "        for i in range(1, num_samples + 1):\n",
    "            opt_key = f'opt{i}'\n",
    "            final_translation_coordinate[opt_key] = {'x': 0, 'y': 0, 'z': 0}\n",
    "            current_matrix = matrix_base[:]  # Work with a copy of the base matrix for each sample\n",
    "            \n",
    "            new_matrix[opt_key] = current_matrix  # Assign the copy of the base matrix to the option key\n",
    "            \n",
    "            for idx, key in zip([3, 7, 11], ['x', 'y', 'z']):\n",
    "                random_translation = (2 * random.random() - 1) * max_translation\n",
    "                current_matrix[idx] += random_translation * 10  # Apply translation and convert to mm\n",
    "                final_translation_coordinate[opt_key][key] = random_translation * 10  # Store translation in mm\n",
    "            \n",
    "        return new_matrix, final_translation_coordinate\n",
    "\n",
    "\n",
    "    def extract_details(self):\n",
    "        examinations_transformations = []\n",
    "\n",
    "        # Interested only in the examination part of the JSON file\n",
    "        for exam_name, exam_details in self.data['examinations'].items():\n",
    "            if 'pCT' not in exam_name:\n",
    "                exam_dict = {'exam_name': exam_name, 'plans': []}  # Initialize with an empty plans list\n",
    "                reg_to_planning = exam_details.get('registration_to_planning_examinations', {})\n",
    "\n",
    "                for plan_name, registration_details in reg_to_planning.items():\n",
    "\n",
    "                    # if 'F' not in plan_name:\n",
    "                    if 'P' in plan_name:\n",
    "                        from_exam = registration_details.get('from_examination_name')\n",
    "                        to_exam = registration_details.get('to_examination_name')\n",
    "                        rigid_matrix = registration_details.get('rigid_transformation_matrix', [])\n",
    "\n",
    "                        if rigid_matrix:\n",
    "                            new_matrix, final_translation_coordinate = self.new_transfer_param(rigid_matrix)\n",
    "                            \n",
    "                            plan_dict = {\n",
    "                                'plan_name': plan_name,\n",
    "                                'planning_exam_name': to_exam,\n",
    "                                'repeatedCT_name': from_exam,\n",
    "                                'transformation_matrix': new_matrix,\n",
    "                                'final_translation_coordinate': final_translation_coordinate\n",
    "\n",
    "                            }\n",
    "                            exam_dict['plans'].append(plan_dict)  # Add this plan to the exam's plans list\n",
    "                            print(plan_dict)\n",
    "                if exam_dict['plans']:  # Only append if there are any plans\n",
    "                    examinations_transformations.append(exam_dict)\n",
    "\n",
    "        return examinations_transformations\n",
    "\n",
    "\n",
    "    def get_plan_details(self):\n",
    "        return self.examinations_transformations\n",
    "    \n",
    "\n",
    "    def save_to_json(self, output_file):\n",
    "        data_to_save = {\n",
    "        \"id\": self.id,\n",
    "        \"examination_details\": self.examinations_transformations\n",
    "    }\n",
    "        with open(output_file, 'w') as file:\n",
    "            json.dump(data_to_save, file, indent=4)\n",
    "\n",
    "# # Usage example\n",
    "# case_data_path = \"/home/shahpouriz/Data/DBP_CTs/DBP_OP011_case_data.json\"\n",
    "# patient = CaseDataReader(case_data_path)\n",
    "\n",
    "# examinations_transformations = patient.get_plan_details()\n",
    "# patient.save_to_json('/home/shahpouriz/Data/DBP_CTs/DBP_OP011_coordination_data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "# Define the root directory to search for case_data.json files\n",
    "case_data_root = \"/home/shahpouriz/Data/TEST/\"\n",
    "\n",
    "# Use glob to find all *case_data.json files in the directory and its subdirectories\n",
    "case_data_files = glob.glob(os.path.join(case_data_root, '**', '*case_data.json'), recursive=True)\n",
    "\n",
    "for case_data_path in case_data_files:\n",
    "    patient = CaseDataReader(case_data_path)\n",
    "\n",
    "    examinations_transformations = patient.get_plan_details()\n",
    "    \n",
    "    # Generate the new file name based on the original file name\n",
    "    # Here, we replace '_case_data.json' with '_coordination_data.json'\n",
    "    new_file_name = case_data_path.replace('_case_data.json', '_coordination_data.json')\n",
    "    \n",
    "    # Optionally, ensure the directory exists or create it\n",
    "    output_directory = os.path.dirname(new_file_name)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Save the processed data to the new file\n",
    "    patient.save_to_json(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def process_examination_transformations(examinations_transformations, root_patient, saving_root_patient):\n",
    "    \"\"\"\n",
    "    Process examination transformations for a given patient.\n",
    "\n",
    "    Parameters:\n",
    "    - examinations_transformations: List of examination transformations loaded from a JSON file.\n",
    "    - root_patient: Base directory path where patient's DICOM files are located.\n",
    "    - saving_root_patient: Directory path where processed data will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    for item in examinations_transformations:\n",
    "        exam_name = item.get('exam_name')\n",
    "        for plan in item.get('plans', []):\n",
    "            plan_name = plan.get('plan_name')\n",
    "            moving_CT = plan.get('repeatedCT_name')\n",
    "            fixed_CT = plan.get('planning_exam_name')\n",
    "\n",
    "            for opt in ['opt1', 'opt2']:\n",
    "                transformation_matrix = np.array(plan.get('transformation_matrix', {}).get(opt, [])).reshape(4, 4)\n",
    "\n",
    "            \n",
    "                print(f\"Exam: {exam_name}, Plan: {plan_name}\")\n",
    "                print(f\"Moving CT: {moving_CT}, Fixed (Planning) CT: {fixed_CT}\")\n",
    "                print(f\"Transformation Matrix: {transformation_matrix}\")\n",
    "                print(\"--------------------------------------------------\")\n",
    "                \n",
    "                path_fixed_CT = os.path.join(root_patient, fixed_CT, '')\n",
    "                path_moving_CT = os.path.join(root_patient, moving_CT, '')\n",
    "\n",
    "                if not os.path.exists(path_fixed_CT) or not os.path.exists(path_moving_CT):\n",
    "                    warnings.warn(f\"Path does not exist: {path_fixed_CT if not os.path.exists(path_fixed_CT) else path_moving_CT}\")\n",
    "                    continue  # Skip th\n",
    "\n",
    "                path_struct_fixed_CT = get_path_structures_DICOM_file(path_fixed_CT)\n",
    "                path_struct_moving_CT = get_path_structures_DICOM_file(path_moving_CT)\n",
    "\n",
    "                fixed_CT_obj = construct_CT_object(fixed_CT, path_fixed_CT, path_struct_fixed_CT, roi_names=['External'])\n",
    "                moving_CT_obj = construct_CT_object(moving_CT, path_moving_CT, path_struct_moving_CT, roi_names=['External'])\n",
    "\n",
    "                \n",
    "                moving_CT_obj.transform(transformation_matrix, fixed_CT_obj)\n",
    "                \n",
    "\n",
    "                fixed_CT_obj.override_air_outside_external()\n",
    "                moving_CT_obj.override_air_outside_external()\n",
    "\n",
    "                fixed_ct_saving_path = os.path.join(saving_root_patient, plan_name, opt, fixed_CT_obj.name)\n",
    "                moving_ct_saving_path = os.path.join(saving_root_patient, plan_name, opt, moving_CT_obj.name)\n",
    "\n",
    "                plan['planningCT_filename'][opt] = fixed_ct_saving_path\n",
    "                plan['repeatedCT_filename'][opt] = moving_ct_saving_path\n",
    "\n",
    "\n",
    "                # fixed_CT_array = sitk.GetArrayFromImage(fixed_CT_obj.image)\n",
    "                # moving_CT_array = sitk.GetArrayFromImage(moving_CT_obj.image)\n",
    "                # plt.imshow(fixed_CT_array[80]-moving_CT_array[80])\n",
    "                \n",
    "                if not os.path.exists(fixed_ct_saving_path):\n",
    "                    os.makedirs(fixed_ct_saving_path, exist_ok=True)\n",
    "                    fixed_CT_obj.save(fixed_ct_saving_path, save_struct_file=False)\n",
    "\n",
    "                os.makedirs(moving_ct_saving_path, exist_ok=True)\n",
    "                moving_CT_obj.save(moving_ct_saving_path, save_struct_file=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'new_env (Python 3.11.5)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory where the coordination JSON files are saved\n",
    "coordination_json_root = \"/home/shahpouriz/Data/TEST/\"\n",
    "\n",
    "# Use glob to find all *_coordination_data.json files in the directory\n",
    "coordination_json_files = glob.glob(os.path.join(coordination_json_root, '**', '*_coordination_data.json'), recursive=True)\n",
    "\n",
    "for json_file in coordination_json_files:\n",
    "    # Load the JSON content\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "\n",
    "    patient_id = data[\"id\"]  # Assuming the patient ID is stored at the top level\n",
    "    examinations_transformations = data[\"examination_details\"]  # The list of transformations\n",
    "    root_patient = os.path.join(\"/data/oosterhoff/patients/\", patient_id)\n",
    "\n",
    "    \n",
    "\n",
    "    saving_root_patient = os.path.join(coordination_json_root, patient_id)\n",
    "\n",
    "    process_examination_transformations(examinations_transformations, root_patient, saving_root_patient)\n",
    "\n",
    "\n",
    "    with open(json_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
