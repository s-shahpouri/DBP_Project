{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from dual_network import Dual3DCNN3, Dual3DCNN4, Dual3DCNN5\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import glob\n",
    "from utilities import create_list_from_master_json, read_json_file, split_data\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from utilities import list_patient_folders, prepare_data_nrrd, split_data\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Spacingd, ScaleIntensityd, SpatialPadd, CenterSpatialCropd, ScaleIntensityRanged\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.transforms import LoadImaged\n",
    "from monai.data.image_reader import ITKReader\n",
    "from monai.data import SmartCacheDataset\n",
    "import random\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 320\n",
      "Number of validation samples: 89\n",
      "Number of test samples: 81\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "data_path_NEW = '/home/shahpouriz/Data/DBP_newDATA/DBP/nrrd/test'\n",
    "\n",
    "\n",
    "patient_list_NEW = list_patient_folders(data_path_NEW)\n",
    "# Shuffle patient list if you want randomness\n",
    "random.shuffle(patient_list_NEW)\n",
    "\n",
    "# Define split sizes\n",
    "total_patients = len(patient_list_NEW)\n",
    "train_size = int(total_patients * 0.70)\n",
    "val_size = int(total_patients * 0.20)\n",
    "# The rest will be for the test set\n",
    "\n",
    "# Split the patient list\n",
    "train_patients = patient_list_NEW[:train_size]\n",
    "val_patients = patient_list_NEW[train_size:train_size + val_size]\n",
    "test_patients = patient_list_NEW[train_size + val_size:]\n",
    "\n",
    "train_pct, train_rct, train_pos = prepare_data_nrrd(data_path_NEW, train_patients)\n",
    "val_pct, val_rct, val_pos = prepare_data_nrrd(data_path_NEW, val_patients)\n",
    "test_pct, test_rct, test_pos = prepare_data_nrrd(data_path_NEW, test_patients)\n",
    "\n",
    "# Create dictionaries for each dataset\n",
    "train_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(train_pct, train_rct, train_pos)]\n",
    "val_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(val_pct, val_rct, val_pos)]\n",
    "test_data = [{\"plan\": img, \"repeat\": tar, \"pos\": pos} for img, tar, pos in zip(test_pct, test_rct, test_pos)]\n",
    "\n",
    "\n",
    "# Check the lengths of the sets\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(val_data))\n",
    "print(\"Number of test samples:\", len(test_data))\n",
    "print(len(test_data)+len(val_data)+len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 256/256 [00:37<00:00,  6.75it/s]\n",
      "Loading dataset: 100%|██████████| 71/71 [00:10<00:00,  6.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dual3DCNN5(\n",
       "  (input_fixed_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(16, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(32, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(128, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(256, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (input_moving_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(16, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(32, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(128, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): Conv3d(256, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dim = 128\n",
    "size = (dim, dim, dim)\n",
    "pixdim = (3.0, 3.0, 3.0)\n",
    "transforms = Compose([\n",
    "        LoadImaged(keys=[\"plan\", \"repeat\"], reader=ITKReader()),\n",
    "        EnsureChannelFirstd(keys=[\"plan\", \"repeat\"]),\n",
    "        ScaleIntensityd(keys=[\"plan\", \"repeat\"]),\n",
    "        Spacingd(keys=[\"plan\", \"repeat\"], pixdim=pixdim, mode='trilinear'),\n",
    "        SpatialPadd(keys=[\"plan\", \"repeat\"], spatial_size=size, mode='constant'),  # Ensure minimum size\n",
    "        CenterSpatialCropd(keys=[\"plan\", \"repeat\"], roi_size=size),  # Ensure uniform size\n",
    "    ])\n",
    "\n",
    "\n",
    "train_ds = CacheDataset(data=train_data, transform=transforms, cache_rate=0.8, num_workers=1)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "val_ds = CacheDataset(data=val_data, transform=transforms, cache_rate=0.8, num_workers=1)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "model = Dual3DCNN5(width=dim, height=dim, depth=dim)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "starting_epoch = 0\n",
    "final_epoch = 2\n",
    "\n",
    "# Condition for saving list\n",
    "best_mae = np.inf\n",
    "exception_list = ['']\n",
    "mae_loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 14:31:57,482] A new study created in memory with name: no-name-5d73c6d5-2b86-4821-b676-5dcd995a9c5e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 14:32:36,741] Trial 0 finished with value: 0.22764338837580733 and parameters: {'lr': 2.9862034252760157e-05}. Best is trial 0 with value: 0.22764338837580733.\n",
      "[I 2024-03-13 14:33:17,953] Trial 1 finished with value: 0.20791751846378104 and parameters: {'lr': 0.0015962784379023476}. Best is trial 1 with value: 0.20791751846378104.\n",
      "[I 2024-03-13 14:34:20,875] Trial 2 finished with value: 0.21020508756379733 and parameters: {'lr': 0.010165108285484545}. Best is trial 1 with value: 0.20791751846378104.\n",
      "[I 2024-03-13 14:35:23,806] Trial 3 finished with value: 0.20735523947305307 and parameters: {'lr': 0.016827959619010308}. Best is trial 3 with value: 0.20735523947305307.\n",
      "[I 2024-03-13 14:36:26,785] Trial 4 finished with value: 0.2067016278618549 and parameters: {'lr': 5.742814249611241e-05}. Best is trial 4 with value: 0.2067016278618549.\n",
      "[I 2024-03-13 14:37:29,956] Trial 5 finished with value: 0.20707001745324122 and parameters: {'lr': 0.006575352851050944}. Best is trial 4 with value: 0.2067016278618549.\n",
      "[I 2024-03-13 14:38:33,209] Trial 6 finished with value: 0.20605043974820147 and parameters: {'lr': 0.00010285678061919842}. Best is trial 6 with value: 0.20605043974820147.\n",
      "[I 2024-03-13 14:39:36,126] Trial 7 finished with value: 0.2411969362056992 and parameters: {'lr': 0.09421207389426449}. Best is trial 6 with value: 0.20605043974820147.\n",
      "[I 2024-03-13 14:40:39,218] Trial 8 finished with value: 0.20497857394701477 and parameters: {'lr': 0.0018966257353212146}. Best is trial 8 with value: 0.20497857394701477.\n",
      "[I 2024-03-13 14:41:42,428] Trial 9 finished with value: 0.20563467505147284 and parameters: {'lr': 0.0018248005380921723}. Best is trial 8 with value: 0.20497857394701477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 8\n",
      "Best value (validation loss): 0.20497857394701477\n",
      "Best hyperparameters: {'lr': 0.0018966257353212146}\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def objective(trial, model, train_loader, val_loader, device, final_epoch, mae_loss):\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(starting_epoch, final_epoch):\n",
    "        model.train()  # Set model to training mode\n",
    "        mae_list = []\n",
    "        train_loss = []\n",
    "        for i, batch_data in enumerate(train_loader):  # Use enumerate to get the batch index\n",
    "            pCT, rCT = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "            reg = batch_data[\"pos\"].clone().detach().requires_grad_(True).to(device)  # If gradients are required for 'reg'\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(pCT, rCT)\n",
    "            loss_output = mae_loss(output, reg)\n",
    "\n",
    "            loss_output.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Logging\n",
    "            mae_list.append(loss_output.item())\n",
    "            mean_mae = np.mean(mae_list)\n",
    "            # Corrected to print the current batch number\n",
    "\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            for batch_data in val_loader:\n",
    "                pCT_val, rCT_val = batch_data[\"plan\"].to(device), batch_data[\"repeat\"].to(device)\n",
    "                reg_val = batch_data[\"pos\"].clone().detach().requires_grad_(True).to(device)  # If gradients are required for 'reg'\n",
    "\n",
    "                output_val = model(pCT_val, rCT_val)\n",
    "                loss_output_val = mae_loss(output_val, reg_val)\n",
    "\n",
    "                val_loss.append(loss_output_val.item())\n",
    "\n",
    "            mean_val_loss = np.mean(val_loss)\n",
    "    return mean_val_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use functools.partial to pass extra arguments to the objective function\n",
    "objective_with_args = functools.partial(\n",
    "    objective,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    final_epoch=final_epoch,\n",
    "    mae_loss=mae_loss,\n",
    "\n",
    ")\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_with_args, n_trials=10) \n",
    "\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (validation loss):\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2024-03-13 12:57:48,637] A new study created in memory with name: no-name-2cd05e81-8e1c-44d3-81a4-4be74941161f\n",
    "[I 2024-03-13 12:58:47,573] Trial 0 finished with value: 0.309533763534079 and parameters: {'lr': 9.218304386771182e-06}. Best is trial 0 with value: 0.309533763534079.\n",
    "[I 2024-03-13 12:59:54,444] Trial 1 finished with value: 0.3092626925185323 and parameters: {'lr': 6.610746908388528e-05}. Best is trial 1 with value: 0.3092626925185323.\n",
    "[I 2024-03-13 13:01:01,542] Trial 2 finished with value: 0.30921216851100325 and parameters: {'lr': 2.4698381067064442e-05}. Best is trial 2 with value: 0.30921216851100325.\n",
    "[I 2024-03-13 13:02:08,653] Trial 3 finished with value: 0.3096086760734518 and parameters: {'lr': 0.0007246235392743511}. Best is trial 2 with value: 0.30921216851100325.\n",
    "[I 2024-03-13 13:03:15,620] Trial 4 finished with value: 0.3095567206541697 and parameters: {'lr': 1.2856561858081072e-05}. Best is trial 2 with value: 0.30921216851100325.\n",
    "[I 2024-03-13 13:04:22,598] Trial 5 finished with value: 0.3095563782254855 and parameters: {'lr': 8.659948648935581e-08}. Best is trial 2 with value: 0.30921216851100325.\n",
    "[I 2024-03-13 13:05:29,773] Trial 6 finished with value: 0.3095362058530251 and parameters: {'lr': 4.637608822923589e-06}. Best is trial 2 with value: 0.30921216851100325.\n",
    "[I 2024-03-13 13:06:36,824] Trial 7 finished with value: 0.3088546040095389 and parameters: {'lr': 0.0002332795188029022}. Best is trial 7 with value: 0.3088546040095389.\n",
    "[I 2024-03-13 13:07:44,302] Trial 8 finished with value: 0.3088908504260083 and parameters: {'lr': 0.0002125349283948824}. Best is trial 7 with value: 0.3088546040095389.\n",
    "[I 2024-03-13 13:08:51,713] Trial 9 finished with value: 0.30929054742679 and parameters: {'lr': 0.0006778213291587758}. Best is trial 7 with value: 0.3088546040095389.\n",
    "Best trial: 7\n",
    "Best value (validation loss): 0.3088546040095389\n",
    "Best hyperparameters: {'lr': 0.0002332795188029022}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
